%\pdfoutput=1

\documentclass{l4proj}

%
% put any packages here
%

\usepackage{float}
\usepackage[labelfont=bf]{caption}

\usepackage{textcomp}

\usepackage{subfigure}

\usepackage{cleveref}

\usepackage[backend=bibtex,style=numeric]{biblatex}  %backend=biber is 'better'

\usepackage[justification=centering]{caption}

\usepackage[nottoc,notlot,notlof]{tocbibind}

\usepackage{pstricks, pst-node}

\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{algorithmic}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{url}
\usepackage{alltt}
\urldef{\mailsa}\path|pat@dcs.gla.ac.uk|
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}
\newlength{\halftextwidth}
\setlength{\halftextwidth}{0.47\textwidth}

\usepackage{amsopn}
\DeclareMathOperator{\mod}{mod}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}


\renewcommand{\figurename}{Fig.}
\Crefformat{figure}{#2Fig.~#1#3}
\Crefmultiformat{figure}{Figs.~#2#1#3}{ and~#2#1#3}{, #2#1#3}{ and~#2#1#3}

\usepackage{listings}

\usepackage[thinlines]{easytable}

\usepackage{color, colortbl}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{
  %frame=tb,
  language=Java,
  %aboveskip=3mm,
  %belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  %basicstyle={\small\ttfamily},
  basicstyle=\scriptsize,     % the size of the fonts that are used for the code  
  numbers=left,
  stepnumber=1,
  numberstyle=\small\color{gray},    % the size of the fonts that are used for the line-numbers
  numbersep=10pt,             % how far the line-numbers are from the code
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,            % sets automatic line breaking
  breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
  showstringspaces=false,     % Don't show underscores as space characters
  %tabsize=4,
  frame=trBL,                 % adds a frame around the code
  frameround=fttt,
  captionpos=b,               % sets the caption-position to bottom
}

\RequirePackage{filecontents}
\begin{filecontents}{mybib.bib}
  @manual{choco,
  author        = {Charles Prud'homme and Jean-Guillaume Fages and Xavier Lorca},
  title         = {Choco Documentation},
  year          = {2015},
  organization  = {TASC INRIA Rennes LINA CNRS UMR 6241 COSLING S.A.S.},
  timestamp     = {Thu, 11 May 2015},
  url           = {http://www.choco-solver.org },
}
  
  @article{colbourn1984complexity,
  title={The complexity of completing partial Latin squares},
  author={Colbourn, Charles J},
  journal={Discrete Applied Mathematics},
  volume={8},
  number={1},
  pages={25--30},
  year={1984},
  publisher={Elsevier}
}

  @article{mackworth1977consistency,
  title={Consistency in networks of relations},
  author={Mackworth, Alan K},
  journal={Artificial intelligence},
  volume={8},
  number={1},
  pages={99--118},
  year={1977},
  publisher={Elsevier}
}

  @article{gent2008generalised,
  title={Generalised arc consistency for the alldifferent constraint: An empirical survey},
  author={Gent, Ian P and Miguel, Ian and Nightingale, Peter},
  journal={Artificial Intelligence},
  volume={172},
  number={18},
  pages={1973--2000},
  year={2008},
  publisher={Elsevier}
}

  @article{hopcroft1973n,
  title={An n\^{}5/2 algorithm for maximum matchings in bipartite graphs},
  author={Hopcroft, John E and Karp, Richard M},
  journal={SIAM Journal on computing},
  volume={2},
  number={4},
  pages={225--231},
  year={1973},
  publisher={SIAM}
}

@article{crook2009pencil,
  title={A pencil-and-paper algorithm for solving Sudoku puzzles},
  author={Crook, JF},
  journal={Notices of the AMS},
  volume={56},
  number={4},
  pages={460--468},
  year={2009}
}

  @inproceedings{gomes2002completing,
  title={Completing quasigroups or latin squares: A structured graph coloring problem},
  author={Gomes, Carla and Shmoys, David},
  booktitle={proceedings of the Computational Symposium on Graph Coloring and Generalizations},
  pages={22--39},
  year={2002}
}

@inproceedings{simonis2005sudoku,
  title={Sudoku as a constraint problem},
  author={Simonis, Helmut},
  booktitle={CP Workshop on modeling and reformulating Constraint Satisfaction Problems},
  volume={12},
  pages={13--27},
  year={2005},
  organization={Citeseer}
}

  @inproceedings{stergiou1999difference,
  title={The difference all-difference makes},
  author={Stergiou, Kostas and Walsh, Toby},
  booktitle={IJCAI},
  volume={99},
  pages={414--419},
  year={1999}
}

  @online{tarjanart,
  author = {Robert Tarjan},
  title = {HP Labs - Inventor interview - Robert Tarjan : The art of the algorithm},
  year = 2004,
  organization = {},
  file = {:./references/HP Labs - Inventor interview - Robert Tarjan : The art of the algorithm.html:html},
  url = {http://www.hpl.hp.com/news/2004/oct_dec/tarjan.html},
  urldate = {2016-03-14}
  }
  
@article{tarjan1972depth,
  title={Depth-first search and linear graph algorithms},
  author={Tarjan, Robert},
  journal={SIAM journal on computing},
  volume={1},
  number={2},
  pages={146--160},
  year={1972},
  publisher={SIAM}
}

@article{ford1956maximal,
  title={Maximal flow through a network},
  author={Ford, Lester R and Fulkerson, Delbert R},
  journal={Canadian journal of Mathematics},
  volume={8},
  number={3},
  pages={399--404},
  year={1956}
}

@inproceedings{regin1994filtering,
  title={A filtering algorithm for constraints of difference in CSPs},
  author={R{\'e}gin, Jean-Charles},
  booktitle={AAAI},
  volume={94},
  pages={362--367},
  year={1994}
}

@article{berge1957two,
  title={Two theorems in graph theory},
  author={Berge, Claude},
  journal={Proceedings of the National Academy of Sciences},
  volume={43},
  number={9},
  pages={842--844},
  year={1957},
  publisher={National Acad Sciences}
}

@article{haralick1980increasing,
  title={Increasing tree search efficiency for constraint satisfaction problems},
  author={Haralick, Robert M and Elliott, Gordon L},
  journal={Artificial intelligence},
  volume={14},
  number={3},
  pages={263--313},
  year={1980},
  publisher={Elsevier}
}

\end{filecontents}

\addbibresource{mybib.bib}

\begin{document}

\title{Animating a Sudoku Solver}
\author{Gabriel Ionut Stratan}
\date{March 25, 2016}
\maketitle

\begin{abstract}
This report introduces and explains general concepts and algorithms from Constraint Programming that were used throughout the project. The project consists of developing an animated visualization of the \textit{all-different} algorithm introduced by Jean-Charles R\'egin \cite{regin1994filtering} in 1994. The Sudoku puzzle was chosen to illustrate the algorithm as it represents a simple enough problem that uses a great number of constraints of difference for the rows, columns and sub-squares. A full implementation of the \textit{all-different} algorithm is provided in this report, which can be easily adapted to solve problems such as scheduling, timetabling and supply chain management. Finally, this report concludes with the implementation of the Java program that will be used by lecturers and students to visualize how this powerful algorithm works.
\end{abstract}

\educationalconsent
%
%NOTE: if you include the educationalconsent (above) and your project is graded an A then
%      it may be entered in the CS Hall of Fame
%
\tableofcontents
%==============================================================================
\chapter{Introduction}
\label{chap1intro}
\pagenumbering{arabic}

\noindent The Sudoku puzzle is a well known combinatorial problem where the goal is to fill in a partially completed $9 \times 9$ grid with digits from $1$ to $9$ in such a way that a single digit cannot appear twice in the same row, column or $3\times 3$ sub-square. The puzzle is a type of a Latin square that was shown to be NP-complete by Charles Colbourn \cite{colbourn1984complexity} and will be used as an example to introduce the concepts of the all-different algorithm used in Constraint Programming to solve many hard combinatorial problems. Students new to Constraint Programming will be shown a new way of approaching and solving real-world problems by thinking in terms of constraints that impose restrictions on what values variables can take.

\section{Aims}
\noindent The aim of this project is to visualize how Constraint Programming techniques can be used to solve Sudoku puzzles. A Java program is developed to act as a teaching aid to be used by the lecturer to show students how the all-different algorithm works towards a solution. Sudoku puzzles represent an excellent choice to introduce the concept of the all-different constraint in an engaging experience with the students. Students will be shown how to model the Sudoku puzzle as a Constraint Satisfaction Problem and get to the solution without resorting to guessing or brute forcing. The constraint programming technique that will be used to solve the Sudoku puzzle is the same algorithm used worldwide to solve planning, scheduling, timetabling and supply chain management problems. The step by step visual representation of how the algorithm progresses towards a solution will help students better understand the new algorithm.

\section{Background}
The project will provide a visualization for the all-different algorithm introduced by Jean-Charles R\'egin \cite{regin1994filtering} in 1994. The step by step visualization will show how a Sudoku puzzle is solved using the algorithm. Although the original $9 \times 9$ Sudoku puzzle can be solved in a fraction of a second using a variety of algorithms, the power and effectiveness of the all-different algorithm used in this report can be seen when trying to solve bigger Sudoku grids, where the solution is found in a matter or seconds, rather than hours or days using a less efficient approach \cite{stergiou1999difference}. The all-different algorithm is considered an important milestone in the Constraint Programming field. The algorithm's efficiency comes from pruning the search space of a problem of combinations that break the constraints of the problem. Before the introduction of this algorithm, the standard approach in the field used binary constraints that had a poor performance.

\section{Motivation}
The motivation of this project is to provide a tool that makes it easier for a lecturer to introduce the all-different algorithm to students by providing a step by step view of how the algorithm progresses. Students will find it easier to remember and understand the algorithm through the use of the visualizations. The tool based on the Sudoku puzzle is a great way to visualize an important technique used to solve Constraint Satisfaction Problems and will provide an engaging learning experience to the students.

\section{Report Content}
The rest of this report will provide information on the algorithms used and their implementation in the project.
\begin{itemize}
\item \textbf{Chapter~\ref{chap2background}} covers details about the Sudoku puzzle and Constraint Programming.
\item \textbf{Chapter~\ref{chap3alldiffconstraint}} introduces a powerful constraint of difference.
\item \textbf{Chapter~\ref{chap4alldiffalgos}} explains the two algorithms needed to solve a constraint of difference.
\item \textbf{Chapter~\ref{chap5alldiffdemo}} covers a demonstration of the project solving a Sudoku puzzle.
\item \textbf{Chapter~\ref{chap6implementation}} explains the implementation of the project.
\item \textbf{Chapter~\ref{chap7conclusion}} details the overall achievements of the project.
%appendices
\end{itemize}

\chapter{Background}
\label{chap2background}
\section{Sudoku}
\noindent Sudoku, meaning \textit{single number} in Japanese, is a logic-based, combinatorial puzzle that became mainstream in 1986. Today, many magazines and newspapers from all over the world include a Sudoku puzzle. The aim of the game is to place digits from $1$ to $9$ into a $9 \times 9$ grid, such that the same digit may not appear twice in the same row, column or $3\times 3$ sub-square of the puzzle. A Sudoku puzzle starts as a partially completed grid that has to be filled by the player. Enough clues are provided such that the puzzle has a unique solution. An example of a relatively hard Sudoku puzzle is shown in \ref{sudokugrid1}. Variations of the puzzle include instances featuring $n^2\times n^2$ sized boards with $n\times n$ sub-squares. Since the Sudoku puzzle is known to be NP-complete \cite{colbourn1984complexity}, this means that a general Sudoku requires significantly more computational resources as $n$ increases.

\begin{figure}[H]
%\vspace{-6cm}
\begin{center}
%\hspace{-1.5cm}
\begin{minipage}{6cm}
%\centering
\includegraphics[height=6cm]{sudokugrid.pdf}
\caption{A Sudoku puzzle}
\label{sudokugrid1}
\end{minipage}%
%\hfill
\hspace{2.5cm}
\begin{minipage}{6cm}
%\centering
\includegraphics[trim=0.075cm 0.075cm 0.075cm 0.075cm, height=6cm]{sudokugrid2.pdf}
\caption{The state of the puzzle after the propagation}
\label{sudokugrid2}
\end{minipage}%
\end{center}
\end{figure}

\vspace{-1cm}

\noindent One effective way of solving Sudoku puzzles is by using techniques and algorithms used in Constraint Programming. The puzzle can be modelled as a Constraint Satisfaction Problem \cite{simonis2005sudoku} that has $81$ variables and $27$ all-different constraints, one for each of the $9$ rows, column and $3\times 3$ sub-squares of the puzzle. Each constraint in the Sudoku puzzle represents a relationship between 9 variables that make up a row, column or $3\times 3$ sub-square. Variables that represent clues given in the initial puzzle have a domain that contains a single value, while the unknown variables have the set of digits from $1$ to $9$ as their domain of possible values. Multiple techniques are then used to get to a solution by removing infeasible values from the domain of the variables until each one of them is left with only a single value in their domains, representing the correct assignment in the solution.

\noindent Propagation schemes are used to achieve consistency of the constraints. This means that for each variable that has been solved (has a single digit in its domain of possible values), one can remove that value from the domain of the variables that take part in the same constraints. In the case of the Sudoku puzzle, each variable is part of $3$ all-different constraints, one for the row it takes part in, one for the column, and one for the $3\times 3$ sub-square. Propagation is done starting from the variables representing clues in the initial puzzle, and can trigger iterative calls once other variables have their domain reduced to a single value. The iterative calls stop when no more values can be removed from any of the variables' domains. Easy Sudoku puzzles that have many clues \cite{gomes2002completing} can be solved by using this technique alone.

\noindent Figure \ref{sudokugrid2} shows the state of the initial Sudoku puzzle after the propagation is performed. One can notice that the clues provided in the initial puzzle were enough to find out the correct assignment for two variables (circled in the figure). The rest of the variables had their domains reduced to keep the constraints consistent. Notice the first column that contains two variables that have $\{1, 8\}$ as their domain. This is the place where a human may resort to guessing, and where an intelligent algorithm should be used so one can find a solution to the puzzle. The all-different algorithm notices that values $1$ and $8$ should be assigned to the two variables at a later stage in the solution. This is enough information to decide that neither $1$ nor $8$ can be taken by the rest of the variables in the column. This will result in the variable that has $\{4, 8\}$ as its domain being assigned the value $4$ and will inform the other variables in the same column that they cannot take the value $4$. Since this is known, the variable that had $\{1, 4, 7, 8\}$ as its domain will be forced to take the value $7$ as the rest of the values were previously assigned to other variables. By applying the same all-different algorithm on rows, columns and $3\times 3$ sub-squares, one will eventually find the unique solution without having to resort to any guessing. Since the Sudoku puzzle is an NP-complete problem \cite{colbourn1984complexity}, there is no way to know beforehand which row, column or sub-square to solve next. The advantage of the algorithm is that the search space for a solution is pruned by removing values that will never be part of the solution, making the search much faster.

\section{Constraint Programming}
\noindent Constraints can be found everywhere in our daily life, and represent mathematical abstractions of the dependencies in the physical world. More formally, a constraint is a logical relationship among a number of variables, each with its own domain. The constraint imposes restrictions on the values the variables can take. It is good to note that the values of the variables are not always numeric, a heterogeneous constraint would require a word (string) to have a specific length (numeric). Constraints are declarative as they only specify a relationship that must hold between variables and do not provide an algorithm to enforce the relationship.

\noindent Constraint Programming is the area of Computing Science that solves problems by specifying a list of constraints and then finding solutions that satisfy all the constraints. A Constraint Satisfaction Problem (CSP) can be defined as a triple $\mathcal{P} = \{X, D, C\}$, where $X$ represents a set of $n$ variables $X = \{x_1, x_2,..., x_n\}$, $D$ represents the $n$ domains associated to the $n$ variables $D = \{D_1, D_2,..., D_n\}$  such that $x_i \in D_i$, and finally $C$ represents a set of $t$ constraints $C =  \{C_1, C_2,..., C_t\}$. A constraint $C_i$ restricts the values one or more variables can simultaneously take.

\noindent A solution for a CSP $\mathcal{P}$ is a set of values $S = \{s_1, s_2,..., s_n\}$, such that each variable gets assigned a value from its domain and all the constraints are satisfied at once. The set of all the solutions to the problem is noted as $sol(\mathcal{P})$ for a CSP that has multiple solutions. One may also be interested in finding an optimal solution to the problem, one that for example minimizes the path of a traveling salesman. When $sol(\mathcal{P})$ is equal to the empty set, it means that the original CSP is not satisfiable. This simple representation can be used to model complex real world problems such as planning, scheduling, timetabling, supply chain management and more.

\noindent There are three strategies for solving CSPs: inference, search and learning. If all the variables in the problem have finite domains, this means the search space for a solution is finite and represented by all the possible combinations of the values of the variables. Although one can, in theory, enumerate all the possible combinations, we use inference and search to reduce the search space. Inference techniques remove large subspaces of the search tree through local constraint propagation on the basis that no solutions may be found using a particular value from the domain of a variable. Search techniques, such as backtracking, are used to systematically explore the search space, usually with the use of some heuristics, and reduce the search space whenever a single failure is found. Both strategies are frequently used together and work because a solution to a CSP must have all of its constraints satisfied, therefore a local inconsistency on a subset of the variables will not result in a solution.

\noindent The simplest backtracking search algorithms look for solutions to a CSP by traversing the search tree in a depth-first search manner. At each node of the search tree, a variable is assigned a value from its domain, and the node gets extended with branches for the remaining values in the variable's domain that need to be considered later, as they could be part of a solution. For example, consider a simple CSP problem with three variable $x$, $y$ and $z$. Suppose that the search algorithm already assigned a value to the variable $x$ out of its domain, and it reaches a node representing the variable $y$ with the domain $D_y = \{1, 2, 3\}$. The backtracking search algorithm will generate three branches, each one of them representing the variable $y$ getting instantiated to a value from its domain. For every value assigned to the variable $y$, all the constraints tied to this variable and the previously visited variables are checked to see if they still hold. When the constraints are not satisfied by a selected value for a variable, the algorithm proceeds in assigning and testing the rest of the values in the domain of $y$. Once all the values from the domain of the variable $y$ have been tried, the algorithm will backtrack to the previous variable, $x$ in this case, and assign it the next value from its domain. Note that every time backtracking occurs, subtrees of the search tree will no longer be generated and visited since they will not contain any solutions to the CSP. In the problem mentioned above, the subtree for the values of $z$ is no longer generated and tested as the partial solution made out of some specific values for $x$ and $y$ already violated the constraints of the problem. A complete solution is found once all the variables are assigned values that are allowed by the constraints. If the user is interested in only one solution to the problem, the search will terminate, otherwise the algorithm will continue to explore the search tree for other solutions. In the case the problem has no solutions, the algorithm will terminate after visiting all the possibilities in the search tree.

\noindent The efficiency of the backtracking search algorithm can be improved by performing constraint propagation to maintain consistency between the values of the variables and their associated constraints. Every time a variable\textquotesingle s domain is reduced, constraint propagation is performed on the constraints the variable was part of. Propagation will check all the variables that were in a constraining relationship with the original variable and will remove values from their domain that are inconsistent with the problem requirements. By reducing the domains of the variables, the search tree is pruned and the efficiency of the search increases. The domain of a variable may be reduced to the empty set after propagation, which means that there is no value left for that variable that will satisfy the constraints and therefore backtracking should be initiated. On other occasions, the domain of a variable will be reduced to a single value, which means that the value for the variable is now known and therefore removing the need to search through values that would not lead to a solution. The backtracking search algorithm will resume when the propagation results in no changes to the domains of the variables. Information from constraint propagation is usually incorporated in the search algorithm in form of variable and value ordering heuristics that improve the efficiency of the search even more.

\noindent Variable and value ordering heuristics are ways to improve the backtracking search algorithm by prioritizing the instantiation of some variables and by choosing some values from their domain first. Ordering heuristics are essential to effectively solve hard combinatorial problems. The most popular heuristic is the fail-first approach, something Haralick and Elliot \cite{haralick1980increasing} described as ``To succeed, try first where you are most likely to fail''. The principle is to prioritize the instantiation of variables with the smallest domains of values. This is done such that the branches in the search tree that have no solutions get discovered earlier and pruned to bring a noticeable increase in efficiency later in the search. Consider the worst-case scenario when performing a backtracking search on a problem that has no solutions, the search tree will be much smaller as earlier failure is encouraged, making it faster to prove that a problem has no solutions. In the case of problems that start off with equally sized domains, the fail-first principle can still be applied by prioritizing the instantiation of the variables that take part in many constraints. Once a variable was selected for instantiation, some values from its domain could lead to a solution faster than others. The order values are chosen for assignment to the variables is only relevant when trying to find a single solution to the problem. The reason behind this is that trying to find all the solutions to a problem or proving that there are no solutions would have to traverse all the search space anyway. A heuristic to prioritize values from a domain is to assess the likelihood each value has in getting closer to a solution, a choice that will have minimum impact on the domain of other variables after propagation, therefore increasing the chances of finding a solution faster. 

\noindent Some solutions to a problem are better than others. Consider the NP-hard Traveling Salesman Problem (TSP), where the shortest possible path between some cities should be found. The general approach to the optimization problem is to introduce a constraint that minimizes a variable representing an objective, the length of the path in the case of the TSP. Finding an optimal solution is often hard, and proving optimality of a solution might be impossible for complex combinatorial problems.

\noindent Constraint Programming can be regarded as a form of declarative programming, where a user specifies a problem in terms of its variables, their domains and the constraints that should be satisfied. The computer then solves the given problem using a range of techniques that are general approaches to problem solving which can be applied to all the problems that can be modeled as constraint satisfaction problems.

\noindent The original exercise of finding an algorithm to solve a specific problem is now turned into an exercise of finding the best way to model the problem as a CSP, which can later be solved by the computer. The model can make the difference between efficient solving of a problem or a problem that cannot be solved due to its combinatorial complexity. There are usually many ways in which one can model the same problem, but the efficiency of the solution could be different. Consider a problem in which a number of $g$ guests should be offered a seat at one of the $t$ tables, with the constraint that couples should sit together. One could decide to represent each of the $g$ guests as a variable associated with an initial domain representing a listing of the $t$ tables, from which a choice for the table should be made based on the constraints. Another way to model the same problem is to have a number of $t$ variables representing the tables, each with an initial domain representing a listing of all the guests. The search for a solution would reduce the domains of the variables in both models until there is only a single table in the domains of the variables (for the first model where guests are variables), or in the case of the second model, until all the variables representing tables have the cardinality of their domains reduced to their sitting capacity. Although both models are logically equivalent, one may perform worse than the other because of the way solvers work.

\noindent When modelling a problem, it is important to avoid symmetries in the form of equivalent solutions. Symmetries represent wasted computational resources during the backtracking search that is used to explore symmetrical assignments. One should avoid such symmetries by adding new constraints that will filter out the symmetrical solutions. Such constraints are problem specific. If it is necessary to find all the solutions to a problem, including the equivalent ones, one can easily perform permutations of the variables outside of the search space once the main solutions are found, thus avoiding exploring similar branches in the search tree. In the example problem mentioned above, there are symmetries in the solutions, as the same group of guests will be seated at different tables throughout the solutions. As we know tables are the same in real life and can be easily swapped without violating the constraints, such computations should not be made to improve efficiency of the search.

\noindent Real world problems are often large and over-constrained, which may raise difficulties in modelling them. Most of the time there are conflicting objectives such as trying to maximize the efficiency of a production facility, while minimizing the operational costs. Trade-offs between the constraints should be made to come up with a solution to the problem. Problem decomposition should also used to break a large real world scenario into smaller problems that are easier to solve. Finally, one should consider which model is easier to upgrade when more constraints should be added.

\chapter{The All-Different Constraint}
\label{chap3alldiffconstraint}

\section{Review of Jean-Charles R\'egin\textquotesingle s paper}
\noindent This section will introduce the reader to Jean-Charles R\'egin's paper \cite{regin1994filtering} published in 1994, which describes a filtering algorithm for constraints of difference used in solving CSPs. As mentioned before, because the search for all the solutions to a CSP is NP-complete, there is a justified need to prune the search space both before and during the search for the solutions.

\noindent A constraint of difference is defined as a relationship on a subset of the variables of a problem for which the values that are assigned to them should be all different. Many real world problems require such constraints. The paper starts by recognizing the need for a powerful n-ary constraint of difference, as binary constraints of difference cannot efficiently prune the search space of values for variables that will never be part of a solution, and for most instances it does not delete any value. Before the publication of the paper, the common practice to represent the n-ary constraint of difference was to model it as many binary constraints, one for each pair of variables in the n-ary constraint.

\noindent Consider a CSP problem with tree variables $x$, $y$ and $z$ with their domains $D_x = \{1, 2\}$, $D_y = \{1, 2\}$ and $D_z = \{1, 2, 3\}$ with a constraint that solutions should have different values assigned to the variables. The first way one could model such a problem is by introducing 3 binary constraints of difference for all the pairs of the variables: $\{x, y\}$, $\{x, z\}$ and $\{y, z\}$. The second way, is to use a 3-ary constraint of difference between the variables $\{x, y, z\}$. The difference between the two approaches is that a propagation of the constraints for the binary representation will not reduce the domains of the variables. On the other hand, the model using a 3-ary constraint will successfully remove the value $1$ and $2$ from variable $z$, as they will already be used by $x$ and $y$.

\noindent Jean-Charles R\'egin \cite{regin1994filtering} goes on to describe a generalized constraint of difference to take advantage of the improved pruning of the search space. The aim is to achieve arc-consistency across all the variables in the constraint. A variable $x$ is said to be arc-consistent with the other variables participating in the same n-ary constraint if for all the values in $D_x$, there exists admissible values in the domains of the other variables such that the constraint holds. For the purpose of this exercise, the aim is to achieve diff-arc-consistency, which is concerned with achieving arc-consistency across the constraints of difference.

\noindent A constraint of difference $C$ can be represented by its value graph. The value graph of $C$ is a bipartite graph where the variables in the constraint are grouped in the left partition of the graph, while the right partition represents a union of all the values from the domains of the variables. Edges between the two partitions of the graph connect the variables on the left-hand side with values from their domains.

\noindent \textit{Matches} in the value graph of $C$ are a subset of the edges in the graph, where no two edges share a common vertex. A \textit{maximum match} is when all the vertices in the left partition have an edge to a vertex from the right partition, or more specifically, all the variables in the left partition are assigned a value from the right one.
After finding maximum matchings for all the value graphs associated to the constraints of difference in a given CSP, the values assigned to the variables do not break the diff-arc-consistency for the problem. Since each variable is assigned a value from its domain represented by an edge in the graph, and no two variables are assigned the same value, the diff-arc-consistency for the problem still holds. Knowing this property, an algorithm is built to filter the domains of the variables by removing values that would never be part of a maximum matching, therefore breaking the constraint and not leading to any solutions to the problem. It is good to note that by using the notation mentioned earlier, all the constraints of difference can be represented by their value graphs that have a space complexity in $O(pd)$, where $p$ is the arity of the constraint and $d$ is the maximal cardinality of the domains for the variables in the constraint. Computing maximum matchings in a bipartite graph $G = (X, Y, E)$ can be done using Hopcroft and Karp\textquotesingle s algorithm \cite{hopcroft1973n} or the Ford-Fulkerson algorithm \cite{ford1956maximal}. 

\noindent To begin reducing the domains of the variables, more definitions regarding matches are introduced. First, a vertex is $matched$ if there is an edge connecting it to a vertex in another partition of the graph. Vertices that are not matched are said to be \textit{free}. \textit{Alternating paths} represent paths made of edges that are alternatively matches and free and have a length corresponding to the number of edges in the path. \textit{Vital edges} are edges that are part of all the maximum matchings in the value graph of a constraint.

\noindent Berge\textquotesingle s property \cite{berge1957two} is used to find the edges that are not in any maximum matchings and can therefore be deleted. According to the property, such edges are not vital when starting from an arbitrary maximum matching, as no even alternating paths can be found to include that edge. The algorithm starts by computing a maximum matching for the value graph of a constraint of difference. After this, an algorithm such as the one proposed by Tarjan \cite{tarjan1972depth} is used to find the strongly connected components in the graph. This means that edges in such a component will belong to even alternating paths, as the graph is bipartite and does not have any odd cycles. The step of finding strongly connected components is necessary as this means that every edge connecting vertices from two different strongly connected components can be deleted as it will never be part of an even alternating path. The deletion of an edge in the value graph of the constraint represents the reduction of a variable's domain. The complexity of this algorithm proposed by Jean-Charles R\'egin \cite{regin1994filtering} is of $O(p^2d^2)$ for one constraint of difference.

\noindent Reducing the domain of a variable by deleting edges in the value graph of a constraint can trigger modifications for other constraints involving the same variable. If a variable is part of other constraints of difference, the author shows a more efficient propagation approach than simply repeating the same algorithm. The filtering algorithm for the second constraint builds on the information from the previous step by trying to remove the same edges in the value graph of the new constraint as long as they are not vital and a new maximum matching can be found.

\noindent The paper goes on to solve the zebra problem, a famous logic puzzle. The author models the problem in different ways to prove that his approach can prune the search space of the problem more when compared to the previous methods used in the industry. One representation of the problem uses binary constraints for each pair of variables involved in the constraint of difference and another representation uses the n-ary constraint of difference introduced by the author. 

\noindent The results of his experiment show that the search space of the problem gets pruned more using the approach proposed in the paper, making the search for a solution to the problem more efficient. The same method was successfully used in solving problems such as subgraph isomorphism.

\section{Usage example}
\noindent To demonstrate the usage and effects of the all-different constraint, a simple example that uses the all-different algorithm is provided below. The CSP problem will be modeled in Java and will make use of Choco3 \cite{choco}, a powerful free and open-source Java library used to solve Constraint Satisfaction Problems. The implementation of the all-different constraint in the Choco3 library is based on Jean-Charles R\'egin\textquotesingle s paper \cite{regin1994filtering} reviewed above.

\noindent The problem has three variables $x$, $y$, $z$ with the following initial domains: $x = \{1, 2\}$, $y = \{1, 2\}$ and $z = \{2, 3\}$. The constraint that should be satisfied by all the solutions of the problem is that $x$, $y$ and $z$ should all be different. The Listing 3.1 shows how the problem is modeled and implemented using the Choco3 library.

\vspace*{1cm}

\lstset{
  %frame=tb,
  language=Java,
  %aboveskip=3mm,
  %belowskip=3mm,
  columns=fullflexible,
  %basicstyle={\small\ttfamily},
  basicstyle=\small,     % the size of the fonts that are used for the code  
  numbers=left,
  stepnumber=1,
  numberstyle=\small\color{gray},    % the size of the fonts that are used for the line-numbers
  numbersep=10pt,             % how far the line-numbers are from the code
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,            % sets automatic line breaking
  breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
  showstringspaces=false,     % Don't show underscores as space characters
  %tabsize=4,
  frame=trBL,                 % adds a frame around the code
  frameround=fttt,
  captionpos=b,               % sets the caption-position to bottom
  showspaces=false,
}

\begin{figure}[H]
\lstset{caption={Usage of the all-different constraint in Choco3 \cite{choco}}, label=alldifferentChoco3}
%\lstinputlisting{all-differentExample.java}
\begin{lstlisting}
Solver solver = new Solver("AllDifferentExample");

IntVar x = VF.enumerated("x", new int[]{1, 2}, solver); 
IntVar y = VF.enumerated("y", new int[]{1, 2}, solver);
IntVar z = VF.enumerated("z", new int[]{2, 3}, solver);

solver.post(ICF.alldifferent(new IntVar[]{x, y, z}));

try{
    solver.propagate();
} catch (ContradictionException e){
    // Handle the exception
}

System.out.println(x + "\n" + y + "\n" + z);

if(solver.findSolution()){
    do{
	int x_val = x.getValue();
	int y_val = y.getValue();
	int z_val = z.getValue();

	System.out.println(x_val + "; " + y_val + "; " + z_val);
    } while(solver.nextSolution());
}
\end{lstlisting}
\label{choco3code}
\end{figure}
 
\noindent Line 1 defines a Choco3 solver object, that will store the variables, their domains and constraints associated to them. Lines 3 to 5 define the three integer variables in the problem and their associated initial domains. The reference to the $solver$ object makes sure the variables are added to the model. Line 7 introduces the all-different constraint between the three variables. The constraint is then posted to the model and the CSP is now fully modeled.

\noindent Before trying to find a solution, a call to the \textit{propagate} method is performed on the model on line 10. The propagation algorithm will make all the constraints consistent by looping through all the constraints in the model (only one in this case) with the aim of reducing the domains of the variables by removing values that will never be part of a solution. When a value is removed from the domain of a variable, this might trigger an iterative propagation call on all its dependant variables to make the constraints consistent. The iterative propagation calls end when the problem is in a consistent state. It is good to note that propagation will preserve all the original solutions to the problem, while greatly reducing the search space.

\noindent The \textit{ContradictionException} on line 11 is an exception that is raised by Choco3 whenever a variable is left with an empty domain or is instantiated to a value that is out of its initial domain. This usually happens in overconstrained problems, where there are no values in the domains of the variables that satisfy all the constraints at once. In such cases, there would be no valid solutions to the problem. This is not the case with the example showcased here, as there are three variables with three different values in total.

\noindent Once the propagation is finished, a call is made on line 15 to output the updated domains of the variables. The updated domains after the call to the \textit{propagation} method are as follows: $x = \{1, 2\}$, $y = \{1, 2\}$ and $z = \{3\}$. The variable $z$ lost the value $2$ from its domain, while to the domains of $x$ and $y$ stayed the same. There are two reasons behind removing the value $2$ from the domain of variable $z$. Firstly, there would no solutions with $z$ taking the value of $2$ as this would leave either $x$ or $y$ with an empty domain after one of them takes the value of $1$. Secondly, two variables ($x$ and $y$) have the same domain of $\{1, 2\}$, therefore a solution that is consistent with the all-different constraint will have $x$ taking the value of $1$ and $y$ taking the value of $2$ (or vice-versa), making it impossible for $z$ to take the value of $2$.  Since we know that the values $1$ and $2$ will be attributed to $x$ and $y$, the value $2$ is removed from the domain of $z$ to reflect this change and to reduce the search space.

\noindent Lines 17 to 25 will iterate over the two solutions of the problem and print the values for the variables. The solutions to the problem are $S_1 = \{1, 2, 3\}$ and $S_2 = \{2, 1, 3\}$ and they both contain values for the three variables that satisfy the all-different constraint.

\chapter{Algorithms for All-Different}
\label{chap4alldiffalgos}

\section{Ford-Fulkerson}
\label{ffsection}
\noindent This section introduces an algorithm used to compute a maximum matching in a graph. A \textit{flow} represents a directed graph with special vertices called the \textit{source} and the \textit{sink}. Source vertices have outgoing edges to inner vertices, while sink vertices have incoming edges from inner vertices of the graph. The problem requires sending flows, for example water through a pipe, from the source to the sink, while conserving the equilibrium.

\noindent Flows need to get from the \textit{source} to the \textit{sink} by following the directed edges that often have different maximum capacity constraints, such as the diameter of a water pipe. Given a flow $f$ in graph $G$, a residual directed graph $G_f$ is generated. Forward edges in the graph have not reached their maximum capacity, while backward edges reached their upper bound. 

\noindent The Ford-Fulkerson algorithm  \cite{ford1956maximal} uses the residual graph to achieve a maximum flow in the graph. The algorithm looks for augmenting paths from source $S$ to sink $T$ in a breadth first-search manner. Once a path $p$ is found, the weight that will make the bottleneck edge in $p$ fill its maximum capacity is sent. This is made by adding (subtracting) the weight for each forward (backward) edge in $p$. Forward edges that reach their maximum capacity turn into backward edges. This results in flow $f'$ that has a greater value than before. Berge\textquotesingle s theorem \cite{berge1957two} guarantees that once all the augmenting paths have been successively visited in the algorithm, the end result is a maximum flow of the graph.

\noindent The maximum matching problem is a special case of the maximum flow problem. For the purpose of this project, there will be only one source $S$ that has outgoing edges to the vertices in the left partition $L$ of the bipartite graph and one sink $T$ with incoming edges from the right partition $R$ of the graph. Vertices in $L$ are connected through edges to vertices in $R$. To find a maximum matching for a Graph $G$, the source and sink vertices are added to the graph and all edges are set to have a maximum capacity of $1$. We then run the Ford-Fulkerson algorithm \cite{ford1956maximal} on the graph, by finding all the augmenting paths from free vertices in $L$ to free vertices in $R$.

\noindent For the purpose of this project, if no maximum matching is found in the value graph of the constraint, then one can backtrack immediately as this means that the constraint cannot be satisfied. Having a maximum matching for our graph, the next step in the all-different algorithm is to turn the previously undirected graph, into a directed one. The matches resulted from the Ford-Fulkerson algorithm \cite{ford1956maximal} are assigned a direction from the 1 to 9 values to the corresponding variables of the Sudoku row. The edges that remain unused in the matching are given a direction from left to right (i.e. from the variables of the Sudoku row to the 1-9 values).

%graphffstart
\begin{figure}[H]
%graph1
  %\hfill
  \begin{minipage}{8.5cm}
    \centering
\psset{colsep=1.8cm,rowsep=0.5cm}
\begin{psmatrix}
[mnode=circle]a&1 \\
b&2 \\
c&3 \\
d&4 \\
e&5 \\
[mnode=none]L&[mnode=none]R 

\ncline[linewidth=2pt]{1,1}{1,2} % a > 1
\ncline{1,1}{2,2} % a > 2
\ncline{1,2}{2,1} % b > 1
\ncline{3,1}{2,2}  % c > 2
\ncline[linewidth=2pt]{3,1}{3,2} % c > 3 
\ncline{4,1}{3,2} % d > 3
\ncline[linewidth=2pt]{4,1}{4,2}  % d > 4
\ncline{4,1}{5,2} % d > 5
\ncline[linewidth=2pt]{5,2}{5,1} % e > 5

\end{psmatrix}
\caption{Initial graph}
\label{graph1}
\end{minipage}%
%graph2
\hfill
\begin{minipage}{8.5cm}
\centering
  \psset{colsep=2.0cm,rowsep=0.5cm, arrows=->, arrowsize=6pt, arrowinset=0, labelsep=3pt}
\begin{psmatrix}
&[mnode=circle]a&[mnode=circle]1 \\
&[mnode=circle]b&[mnode=circle]2 \\
[mnode=circle]S&[mnode=circle]c&[mnode=circle]3&[mnode=circle]T\\
&[mnode=circle]d&[mnode=circle]4 \\
&[mnode=circle]e&[mnode=circle]5 \\
[mnode=none]&L&R

\ncline[linecolor=blue]{3,1}{1,2}\mput*{0/1}
\ncline[linecolor=blue]{3,1}{2,2}\mput*{0/1}
\ncline[linecolor=blue]{3,1}{3,2}\mput*{0/1}
\ncline[linecolor=blue]{3,1}{4,2}\mput*{0/1}
\ncline[linecolor=blue]{3,1}{5,2}\mput*{0/1}

\ncline{1,2}{1,3}\mput*{0/1} % a > 1
\ncline{1,2}{2,3}\mput*{0/1} % a > 2
\ncline{2,2}{1,3}\mput*{0/1} % b > 1
\ncline{3,2}{2,3}\mput*{0/1} % c > 2
\ncline{3,2}{3,3}\mput*{0/1} % c > 3
\ncline{4,2}{3,3}\mput*{0/1} % d > 3
\ncline{4,2}{4,3}\mput*{0/1} % d > 4
\ncline{4,2}{5,3}\mput*{0/1} % d > 5
\ncline{5,2}{5,3}\mput*{0/1} % e > 5

\ncline[linecolor=blue]{1,3}{3,4}\mput*{0/1}
\ncline[linecolor=blue]{2,3}{3,4}\mput*{0/1}
\ncline[linecolor=blue]{3,3}{3,4}\mput*{0/1}
\ncline[linecolor=blue]{4,3}{3,4}\mput*{0/1}
\ncline[linecolor=blue]{5,3}{3,4}\mput*{0/1}
\end{psmatrix}
\caption{S\&T vertices added}
\label{graph2}
\end{minipage}%
\vspace*{1cm}
%graph3
%\hfill
%\caption{Title for both}
%\end{figure}

%\begin{figure}[h]
%\hfill
\begin{minipage}{8.5cm}
  \centering
\psset{colsep=2.0cm,rowsep=0.5cm, arrows=->, arrowsize=6pt, arrowinset=0, labelsep=3pt}
\begin{psmatrix}
&[mnode=circle]a&[mnode=circle]1 \\
&[mnode=circle]b&[mnode=circle]2 \\
[mnode=circle]S&[mnode=circle]c&[mnode=circle]3&[mnode=circle]T\\
&[mnode=circle]d&[mnode=circle]4 \\
&[mnode=circle]e&[mnode=circle]5 \\
[mnode=none]&L&R

\ncline[linewidth=2pt, linecolor=red]{1,2}{3,1}\mput*{1/1} 
\ncline{3,1}{2,2}\mput*{0/1}
\ncline[linewidth=2pt, linecolor=red]{3,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt, linecolor=red]{4,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt, linecolor=red]{5,2}{3,1}\mput*{1/1}

\ncline[linewidth=2pt, linecolor=red]{1,3}{1,2}\mput*{1/1} % a > 1
\ncline{1,2}{2,3}\mput*{0/1} % a > 2
\ncline{2,2}{1,3}\mput*{0/1} % b > 1
\ncline[linewidth=2pt, linecolor=red]{2,3}{3,2}\mput*{1/1} % c > 2
\ncline{3,2}{3,3}\mput*{0/1} % c > 3
\ncline[linewidth=2pt, linecolor=red]{3,3}{4,2}\mput*{1/1} % d > 3
\ncline{4,2}{4,3}\mput*{0/1} % d > 4
\ncline{4,2}{5,3}\mput*{0/1} % d > 5
\ncline[linewidth=2pt, linecolor=red]{5,3}{5,2}\mput*{1/1} % e > 5

\ncline[linewidth=2pt, linecolor=red]{3,4}{1,3}\mput*{1/1}
\ncline[linewidth=2pt, linecolor=red]{3,4}{2,3}\mput*{1/1}
\ncline[linewidth=2pt, linecolor=red]{3,4}{3,3}\mput*{1/1}
\ncline{4,3}{3,4}\mput*{0/1}
\ncline[linewidth=2pt, linecolor=red]{3,4}{5,3}\mput*{1/1}
\end{psmatrix}
\caption{Greedy match}
\label{graph3}
\end{minipage}%
%graph4
\hfill
\begin{minipage}{8.5cm}
\centering
  \psset{colsep=2.0cm,rowsep=0.5cm, arrows=->, arrowsize=6pt, arrowinset=0, labelsep=3pt}
\begin{psmatrix}
&[mnode=circle]a&[mnode=circle]1 \\
&[mnode=circle]b&[mnode=circle]2 \\
[mnode=circle]S&[mnode=circle]c&[mnode=circle]3&[mnode=circle]T\\
&[mnode=circle]d&[mnode=circle]4 \\
&[mnode=circle]e&[mnode=circle]5 \\
[mnode=none]&L&R

\ncline[linewidth=2pt]{1,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt, linecolor=green]{3,1}{2,2}\mput*{0/1}
\ncline[linewidth=2pt]{3,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt]{4,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt]{5,2}{3,1}\mput*{1/1}

\ncline[linewidth=2pt, linecolor=red]{1,3}{1,2}\mput*{1/1} % a > 1
\ncline[linewidth=2pt, linecolor=green]{1,2}{2,3}\mput*{0/1} % a > 2
\ncline[linewidth=2pt, linecolor=green]{2,2}{1,3}\mput*{0/1} % b > 1
\ncline[linewidth=2pt, linecolor=red]{2,3}{3,2}\mput*{1/1} % c > 2
\ncline[linewidth=2pt, linecolor=green]{3,2}{3,3}\mput*{0/1} % c > 3
\ncline[linewidth=2pt, linecolor=red]{3,3}{4,2}\mput*{1/1} % d > 3
\ncline[linewidth=2pt, linecolor=green]{4,2}{4,3}\mput*{0/1} % d > 4
\ncline{4,2}{5,3}\mput*{0/1} % d > 5
\ncline[linewidth=2pt]{5,3}{5,2}\mput*{1/1} % e > 5

\ncline[linewidth=2pt]{3,4}{1,3}\mput*{1/1}
\ncline[linewidth=2pt]{3,4}{2,3}\mput*{1/1}
\ncline[linewidth=2pt]{3,4}{3,3}\mput*{1/1}
\ncline[linewidth=2pt, linecolor=green]{4,3}{3,4}\mput*{0/1}
\ncline[linewidth=2pt]{3,4}{5,3}\mput*{1/1}
\end{psmatrix}
\caption{Longer augmenting path}
\label{graph4}
\end{minipage}%

\vspace*{1cm}
%\null\hfill
%graph5
\begin{minipage}{8.5cm}
  \centering
\psset{colsep=2.0cm,rowsep=0.5cm, arrows=->, arrowsize=6pt, arrowinset=0, labelsep=3pt}
\begin{psmatrix}
&[mnode=circle]a&[mnode=circle]1 \\
&[mnode=circle]b&[mnode=circle]2 \\
[mnode=circle]S&[mnode=circle]c&[mnode=circle]3&[mnode=circle]T\\
&[mnode=circle]d&[mnode=circle]4 \\
&[mnode=circle]e&[mnode=circle]5 \\
[mnode=none]&L&R

\ncline[linewidth=2pt]{1,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt]{2,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt]{3,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt]{4,2}{3,1}\mput*{1/1}
\ncline[linewidth=2pt]{5,2}{3,1}\mput*{1/1}

\ncline{1,2}{1,3}\mput*{0/1} % a > 1
\ncline[linewidth=2pt]{2,3}{1,2}\mput*{1/1} % a > 2
\ncline[linewidth=2pt]{1,3}{2,2}\mput*{1/1} % b > 1
\ncline{3,2}{2,3}\mput*{0/1} % c > 2
\ncline[linewidth=2pt]{3,3}{3,2}\mput*{1/1} % c > 3
\ncline{4,2}{3,3}\mput*{0/1} % d > 3
\ncline[linewidth=2pt]{4,3}{4,2}\mput*{1/1} % d > 4
\ncline{4,2}{5,3}\mput*{0/1} % d > 5
\ncline[linewidth=2pt]{5,3}{5,2}\mput*{1/1} % e > 5

\ncline[linewidth=2pt]{3,4}{1,3}\mput*{1/1}
\ncline[linewidth=2pt]{3,4}{2,3}\mput*{1/1}
\ncline[linewidth=2pt]{3,4}{3,3}\mput*{1/1}
\ncline[linewidth=2pt]{3,4}{4,3}\mput*{1/1}
\ncline[linewidth=2pt]{3,4}{5,3}\mput*{1/1}
\end{psmatrix}
\caption{New matching}
\label{graph5}
\end{minipage}%
\hfill
%graph6
\begin{minipage}{8.5cm}
\centering
  \psset{colsep=2.0cm,rowsep=0.5cm}
\begin{psmatrix}
[mnode=circle]a&1 \\
b&2 \\
c&3 \\
d&4 \\
e&5 \\
[mnode=none]L&[mnode=none]R 

\ncline{1,1}{1,2}% a > 1
\ncline[linewidth=2pt]{1,1}{2,2}% a > 2
\ncline[linewidth=2pt]{1,2}{2,1}% b > 1
\ncline{3,1}{2,2}  % c > 2
\ncline[linewidth=2pt]{3,1}{3,2} % c > 3
\ncline{4,1}{3,2} % d > 3
\ncline[linewidth=2pt]{4,1}{4,2}  % d > 4
\ncline{4,1}{5,2} % d > 5
\ncline[linewidth=2pt]{5,2}{5,1} % e > 5
\end{psmatrix}
\caption{Maximum matching}
\label{graph6}
\end{minipage}%
%\null\hfill
\caption{The FordFulkerson algorithm \cite{ford1956maximal}}
\label{fig:ff_1_6}
\end{figure}
%graphffend

% use \mathit to fix italics spacing
\begin{algorithm}[H]
\DontPrintSemicolon
\nl $\textbf{void} ~FordFulkerson(\textbf{Graph}~G)$ \;
\nl \Begin{
\nl $\textbf{Global} ~ \textbf{int} ~ capacity[][] \gets getCapacity(G)$ \;
\nl $\textbf{Global} ~ \textbf{int} ~ n \gets |V(G)|$ \;
\nl $\textbf{Global} ~ \textbf{int} ~ source \gets 0$ \;
\nl $\textbf{Global} ~ \textbf{int} ~ sink \gets n-1$ \;
\nl $\textbf{Global} ~ pred \gets ~new~\textbf{int}[n]$ \;
\nl $\textbf{Global} ~ visited \gets ~new~\textbf{boolean}[n]$ \;
\nl $\textbf{Global} ~ Q \gets ~new~\textbf{Queue}()$ \;
\nl \While {$\mathit{bfs}(G)$}{
\nl $update()$ \;
}

} %begin FordFulkerson

\;
\nl $\textbf{boolean} ~\mathit{bfs}(\textbf{Graph} ~ G)$ \;
\nl \Begin{
\nl $clear(Q) $ \;
\nl $fill(pred, -1) $ \;
\nl $fill(visited, false) $ \;
\nl $enqueue(source, Q) $ \;
\nl $visited[source] \gets ~true $\;
\nl \While {$(\neg isEmpty(Q))$}{
\nl $\textbf{int} ~ v \gets dequeue(Q) $ \;
\nl \lIf {$v = ~ sink $}{ $\textbf{return} ~ true $ }

\nl \For {$w \gets ~ 0 ~ to ~ n $}{
\nl \If {$\neg visited[w] ~ \textbf{and} ~ capacity[v][w] > 0$}{ 
\nl $ pred[w] \gets v$ \;
\nl $ enqueue(w, Q)$ \;
\nl $ visited[w] \gets true$ \;
} %if
} %for
} %while
\nl $\textbf{return} ~ \mathit{false} $ \;
} %begin bfs

\;

\nl $\textbf{void} ~update()$ \;
\nl \Begin{

\nl $\textbf{int} ~ f \gets minCost()$ \;
\nl $\textbf{int} ~ v \gets sink $ \;

\nl \While {$pred[v] \neq -1$}{
\nl $\textbf{int} ~ u \gets pred[v] $ \;
\nl $capacity[u][v] \gets capacity[u][v] - f $ \;
\nl $capacity[v][u] \gets capacity[v][u] + f $ \;
\nl $v \gets u$ \;
} %while

} %begin updateR

\;

\nl $\textbf{int} ~minCost()$ \;
\nl \Begin{

\nl $\textbf{int} ~ minCost \gets \infty $ \;
\nl $\textbf{int} ~ v \gets sink $ \;

\nl \While {$pred[v] \neq -1$}{
\nl $minCost \gets minimum(minCost, capacity[pred[v]][v])$ \;
\nl $v \gets pred[v]$ \;
}
\nl $\textbf{return} ~ minCost$ \;
} %begin updateR

\caption{The Ford-Fulkerson algorithm}
\label{FordFulkersonPC}
\end{algorithm}

\noindent Ford-Fulkerson\textquotesingle s algorithm \cite{ford1956maximal} for finding a maximum flow in a graph is shown in Algorithm \ref{FordFulkersonPC}. The \textit{Ford Fulkerson} procedure on line 1 takes a graph $G$ as an argument and represents the start of the algorithm. The graph passed as an argument holds information about the capacity of each edge. Line 3 stores the capacity of the graph $G$ in a global two-dimensional integer array. The capacity of an edge between vertices $u$, $v$ is stored in $capacity[u][v]$. Line 4 declares an integer $n$ used to store the number of vertices in the given graph. Lines 5 and 6 declare two integers called $source$ and $sink$ representing references to the first and the last vertices in the given graph.

\noindent In line 7 a vertex-indexed array $pred$ is declared that is used to store references to the previous vertex discovered in the breadth-first search tree. Line 8 declares a vertex-indexed array $visited$ used to keep track if a vertex has already been visited in the breadth-first search procedure. Line 9 declares a queue of integers $Q$ used to store vertices in the order they are visited.

\noindent The algorithm consists of repeated calls to the breadth-first search procedure (line 10). In line 11, there is a call to the update procedure to update the capacities of the edges after finding augmenting paths.

\noindent The \textit{breadth-first search} procedure starts at line 12 and takes a graph $G$ as an argument. In lines 14 to 16, the queue $Q$, $pred$ and $visited$ array are reset to their default values. The breadth-first search call always begins from the first vertex, representing the source. This vertex is enqueued on queue $Q$ in line 17 and is marked as visited in line 18.

\noindent Lines 19 to 26 contain a loop performing changes on the queue $Q$ that is used to store the vertices that will make an augmenting path. The loop starts on line 20 by dequeuing a vertex from the queue $Q$ and storing it in $v$. Line 21 forces the breadth-first search procedure to return $true$ when the last vertex in the graph (the sink) is reached. Lines 22 to 26 contain a loop over all the vertices $w$ in the graph. In line 23 a check is performed to see if the discovered vertex $w$ has not been already visited and it gets considered if it still has available capacity. Line 24 stores the index value of $w$\textquotesingle s predecessor in the augmenting path. Line 25 enqueues the discovered vertex $w$ on the queue $Q$ and marks it as visited in line 26. Finally, the breadth-first search procedure returns \textit{false} when no more augmenting paths are found.

\noindent The $update$ procedure at line 28 is used to update the capacities of the edges in the graph to reflect the updated flow. Line 30 declares an integer $f$ used to store the amount of flow to be added along the found path. The value for $f$ is calculated in the $minCost$ procedure at line 37. Line 31 declares an integer $v$, initially representing the sink which is the last vertex in the graph. Lines 32 to 35 contain a loop that updates the capacities of the edges in the augmenting path. Line 33 uses the integer $u$ to store the index of a vertex that is the predecessor of vertex $v$ along the path. Lines 34 and 35 update the flow along the edge from $u$ to $v$ and $v$ to $u$ by the found difference. Finally, $v$ is updated on line 36 to take the value of $u$ such that the while loop continues to change the capacities of the remaining edges along the path.

\noindent The $minCost$ procedure at line 37 is used to find the amount of flow to be sent along the new augmenting path from the sink to the source. The value is equal to the minimum capacity that is still available along the edges of the path. Line 39 declares an integer $minCost$ used to represent the current value of the minimum cost, initialized to a big value. Line 40 declares an integer variable $v$ initially used to store a reference to the sink vertex. Lines 41 to 43 contain a loop over the edges along the path, starting from the sink toward the source. Line 42 updates the value of $minCost$ if the current edge in the loop has a smaller capacity left than what was previously discovered. The $minimum$ procedure returns the minimum of two given integers. Line 43 updates the value of integer $v$ to its predecessor so the loop can continue along the path until it reaches the $source$. At the end of the $minCost$ procedure, the value of the currently found $minCost$ variable is returned.

\newpage

\section{Tarjan\textquotesingle s algorithm}
\label{tarjansection}
\noindent The next step in the all-different algorithm is to find the strongly connected components of the graph. In order to do this, we introduce now Tarjan\textquotesingle s algorithm \cite{tarjan1972depth} for finding strongly connected components (SCCs) in a given graph $G$. A strongly connected component $C$ of a directed graph $G$ is a maximal set of vertices such that every vertex is reachable from every other vertex by following the directed edges.

\noindent The algorithm starts by visiting every vertex in the directed graph in a depth-first search manner. During the search, vertices are added to a stack in the order they are discovered only if they were not already part of the stack.

\noindent There are four kinds of edges in a depth-first traversal: tree edges, forward edges, back edges and cross edges. Tree edges are edges between a vertex and vertices that were not previously visited. Forward edges are from ancestor vertices to descendant vertices that were already visited during the search. Back edges link descendant vertices back to already visited ancestor vertices. Lastly, cross edges represent edges between two vertices that are neither an ancestor nor a descendant for each other, such as the edges between different components of the graph. 

\noindent For each vertex in a graph G, the algorithm keeps track of two properties. The first property we remember is the $index$ of the vertex, its consecutive order of discovery during the depth-first search, a value that will remain constant throughout the algorithm. The second property associated with all the vertices is named $low$ and keeps track of the lowest (oldest) ancestor reachable from their position in the graph. As each vertex of the graph gets discovered in a depth-first search manner, the initial value that $low$ gets assigned is the same as the order the vertex was discovered. The value for $low$ may get changed during the search if an ancestor for the vertex is discovered by following a back edge. After the recursive depth-first search finishes visiting all of a neighbours of a vertex, the vertex's value for $low$ gets updated to the lowest index of its oldest reachable ancestor. If the value for $low$ of a vertex stays the same even after visiting all of its neighbours, then it means it is the root of a strongly connected component or it's an individual vertex that will be a component on its own.

\noindent For the purpose of finding SCCs, every time a vertex is discovered in the search, the vertex is put on a stack $S$. After returning from the recursive DFS calls on all of the adjacent neighbours of vertex, if both $index$ and $low$ have the same value, it means we've finished discovering a SCC. The vertices in the newly discovered strongly connected component will be popped from the stack $S$ until we reach the current vertex representing the root of the SCC. Vertices that are part of other SCCs are still left on the stack as they have different roots represented by the value of $low$.

\noindent \Cref{graph21} shows a bipartite directed graph with 18 vertices. There are 9 backward edges that represent the maximum matching found using the Ford-Fulkerson algorithm \cite{ford1956maximal} in \Cref{ffsection}. The rest of the possible edges are assigned a forward direction. This graph is similar to the graphs that will be generated to represent a row, column or one of the nine sub-grids of the Sudoku puzzle. For example, the left partition of the graph will contain the nine variables of a Sudoku row, and the right partition will contain the digits from 1 to 9. The edges will then link each variable of the row to values that are still available in their domain.

\noindent \Cref{tarjantable} contains the output after running the Tarjan's algorithm \cite{tarjan1972depth} on the graph in \Cref{graph21}. As previously discussed, vertices are visited in a depth-first search manner, in this case starting from the first vertex. Each vertex has two properties associated to it: its order of discovery or $index$, and its oldest reachable ancestor $low$. Initially, both properties take the value of the index, but as the algorithm progresses the values for $low$ may become lower after visiting all of the neighbours of the vertex and finding the oldest (lowest) reachable ancestor. All vertices are pushed on a stack in the order they are visited. Once a back edge is found in the graph, vertices that are currently on the stack get popped including the root of the newly discovered SCC. Note that vertices may still remain on the stack as they will be part of different components that have other roots. As each vertex is made part of a component, its value for $low$ gets updated to a large value to mark it as already part of a component.

\newpage

%graphtstart
\begin{figure}[H]
%graph21
\begin{minipage}{8.0cm}
\centering
\psset{colsep=6cm, rowsep=0.3cm, arrows=->, arrowsize=6pt, arrowinset=0, radius=3cm}
\begin{psmatrix}
[mnode=circle]1&10 \\
2&11 \\
3&12 \\
4&13 \\
5&14 \\
6&15 \\
7&16 \\
8&17 \\
9&18 \\
[mnode=none]L&[mnode=none]R 

\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{1,2}{1,1} % a > 1 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{1,1}{8,2} % a > 8

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{2,1}{2,2} % b > 2
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{3,2}{2,1} % b > 3 X

\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{2,2}{3,1} % c > 2 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{3,1}{3,2} % c > 3

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{4,1}{2,2} % d > 2 
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{4,2}{4,1} % d > 4 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{4,1}{5,2} % d > 5

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{5,1}{4,2} % e > 4 
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{5,1}{5,2} % e > 5
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{6,2}{5,1} % e > 6 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{6,1}{4,2} % f > 4
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{5,2}{6,1} % f > 5 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{6,1}{6,2} % f > 6

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{7,1}{2,2} % g > 2
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{7,2}{7,1} % g > 7 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{7,1}{9,2} % g > 9

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{8,1}{3,2} % h > 3
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{8,1}{7,2} % h > 7
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{8,2}{8,1} % h > 8 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{2,2} % i > 2
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{3,2} % i > 3
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{5,2} % i > 5
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{8,2} % i > 8
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linewidth=2pt]{9,2}{9,1} % i > 9 X

\end{psmatrix}
\caption{An initial graph}
\label{graph21}
\end{minipage}%
%graph22
\hfill
\begin{minipage}{8.0cm}
\centering
\definecolor{applegreen}{rgb}{0.55, 0.71, 0.0}
\definecolor{amber}{rgb}{1.0, 0.75, 0.0}
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{americanrose}{rgb}{1.0, 0.01, 0.24}
%yellow

\psset{colsep=6cm, rowsep=0.3cm, arrows=->, arrowsize=6pt, arrowinset=0, radius=3cm}
\begin{psmatrix}
[mnode=circle][fillstyle=solid,fillcolor=babyblue]1&[fillstyle=solid,fillcolor=americanrose]10 \\
[fillstyle=solid,fillcolor=amber]2&[fillstyle=solid,fillcolor=amber]11 \\
[fillstyle=solid,fillcolor=amber]3&[fillstyle=solid,fillcolor=amber]12 \\
[fillstyle=solid,fillcolor=applegreen]4&[fillstyle=solid,fillcolor=applegreen]13 \\
[fillstyle=solid,fillcolor=applegreen]5&[fillstyle=solid,fillcolor=applegreen]14 \\
[fillstyle=solid,fillcolor=applegreen]6&[fillstyle=solid,fillcolor=applegreen]15 \\
[fillstyle=solid,fillcolor=yellow]7&[fillstyle=solid,fillcolor=yellow]16 \\
[fillstyle=solid,fillcolor=yellow]8&[fillstyle=solid,fillcolor=yellow]17 \\
[fillstyle=solid,fillcolor=yellow]9&[fillstyle=solid,fillcolor=yellow]18 \\
[mnode=none]L&[mnode=none]R 

\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{1,2}{1,1} % a > 1 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{1,1}{8,2} % a > 8

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{2,1}{2,2} % b > 2
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{3,2}{2,1} % b > 3 X

\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{2,2}{3,1} % c > 2 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{3,1}{3,2} % c > 3

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{4,1}{2,2} % d > 2 
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{4,2}{4,1} % d > 4 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{4,1}{5,2} % d > 5

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{5,1}{4,2} % e > 4 
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{5,1}{5,2} % e > 5
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{6,2}{5,1} % e > 6 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{6,1}{4,2} % f > 4
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{5,2}{6,1} % f > 5 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{6,1}{6,2} % f > 6

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{7,1}{2,2} % g > 2
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{7,2}{7,1} % g > 7 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{7,1}{9,2} % g > 9

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{8,1}{3,2} % h > 3
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{8,1}{7,2} % h > 7
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{8,2}{8,1} % h > 8 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{2,2} % i > 2
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{3,2} % i > 3
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{5,2} % i > 5
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{8,2} % i > 8
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{9,2}{9,1} % i > 9 X


\end{psmatrix}
\caption{The components of the graph}
\label{graph22}
\end{minipage}%
%\caption{Tarjan's algorithm}
%\label{fig:ff_1_6} 
\end{figure}
%graphtend

\definecolor{LightCyan}{rgb}{0.88,1,1}
\definecolor{applegreen}{rgb}{0.55, 0.71, 0.0}
\definecolor{amber}{rgb}{1.0, 0.75, 0.0}
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{americanrose}{rgb}{1.0, 0.01, 0.24}

%tabletstart
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
vertex & index & low & stack & new component & color \\
\hline
1& 1 & 1 & [1] & & \cellcolor{babyblue} \\
\hline
17& 2 & 2 & [1, 17] & & \cellcolor{yellow} \\
\hline
8& 3 & 2 & [1, 17, 8] & & \cellcolor{yellow} \\
\hline
12& 4 & 4 & [1, 17, 8, 12] & & \cellcolor{amber} \\
\hline
2& 5 & 4 & [1, 17, 8, 12, 2] & & \cellcolor{amber} \\
\hline
11& 6 & 4 & [1, 17, 8, 12, 2, 11] & & \cellcolor{amber} \\
\hline
3& 7 & 4 & [1, 17, 8, 12, 2, 11, 3] & & \cellcolor{amber} \\
\hline
& & & [1, 17, 8] & [3, 11, 2, 12] & \\
\hline
16& 8 & 2 & [1, 17, 8, 16] & & \cellcolor{yellow} \\
\hline
7& 9 & 2 & [1, 17, 8, 16, 7] & & \cellcolor{yellow} \\
\hline
18& 10 & 2 & [1, 17, 8, 16, 7, 18] & & \cellcolor{yellow} \\
\hline
9& 11 & 2 & [1, 17, 8, 16, 7, 18, 9] & & \cellcolor{yellow} \\
\hline
14& 12 & 12 & [1, 17, 8, 16, 7, 18, 9, 14] & & \cellcolor{applegreen} \\
\hline
6& 13 & 12 & [1, 17, 8, 16, 7, 18, 9, 14, 6] & & \cellcolor{applegreen} \\
\hline
13& 14 & 12 & [1, 17, 8, 16, 7, 18, 9, 14, 6, 13] & & \cellcolor{applegreen} \\
\hline
4& 15 & 12 & [1, 17, 8, 16, 7, 18, 9, 14, 6, 13, 4] & & \cellcolor{applegreen} \\
\hline
15& 16 & 12 & [1, 17, 8, 16, 7, 18, 9, 14, 6, 13, 4, 15] & & \cellcolor{applegreen} \\
\hline
5& 17 & 12 & [1, 17, 8, 16, 7, 18, 9, 14, 6, 13, 4, 15, 5] & & \cellcolor{applegreen} \\
\hline
& & & [1, 17, 8, 16, 7, 18, 9] & [5, 15, 4, 13, 6, 14] & \\
\hline
& & & [1] & [9, 18, 7, 16, 8, 17] & \\
\hline
& & & [] & [1] & \\
\hline
10& 18 & 18 & [10] & & \cellcolor{americanrose} \\
\hline
& & & [] & [10] & \\
\hline
\end{tabular}
\caption{The depth-first search performed in Tarjan\textquotesingle s algorithm \cite{tarjan1972depth}}
\label{tarjantable}
\end{table}
%tabletend

%\vspace*{1cm}

\begin{algorithm}[H]
\DontPrintSemicolon
\nl $\textbf{void} ~\mathit{Tarjan}(\textbf{Graph}~G)$ \;
\nl \Begin{
\nl $\textbf{Global} ~ \textbf{int} ~ index \gets 0 $ \;
\nl $\textbf{Global} ~ \textbf{int} ~ components \gets 0 $ \; %new
\nl $\textbf{Global} ~ \textbf{int} ~ n \gets |V(G)|$ \; %new
\nl $\textbf{Global} ~ S \gets ~new~\textbf{Stack}()$ \;
\nl $\textbf{Global} ~ stacked \gets ~new~\textbf{boolean}[n]$ \;
\nl $\textbf{Global} ~ id \gets ~new~\textbf{int}[n]$ \;
\nl $\textbf{Global} ~ low \gets ~new~\textbf{int}[n]$ \;

\nl \For {$u \in ~V(G)$}{
\nl \lIf {$\neg stacked[u]$}{ $ \mathit{dfs}(u, G) $ }
}
}
\;
\nl $\textbf{void} ~\mathit{dfs}(\textbf{int}~u, \textbf{Graph}~G)$ \;
\nl \Begin{
\nl $push(u, S) $ \;
\nl $stacked[u] \gets ~true $\;
\nl $low[u] \gets ~index $ \;
\nl $index \gets index + 1$ \;
\nl $\textbf{int} ~ min \gets low[u] $ \;

\nl \For {$v \in ~ N(u, G)$}{
\nl \lIf {$\neg stacked[v]$}{ $\mathit{dfs}(v, G) $ }
\nl $ min \gets minimum(low[v], min) $
 }
\nl $ low[u] \gets minimum(low[u], min) $

\nl $\textbf{integer} ~ v $ \;

\nl \Repeat{\nl $v \neq u$}{
\nl $v \gets pop(S) $ \;
\nl $id[v] \gets components $ \;
\nl $low[v] \gets n $ \;
 }

\nl $ components \gets components + 1 $ \;

}
\caption{Tarjan\textquotesingle s algorithm \cite{tarjan1972depth} for finding the Strongly Connected Components of a Graph}
\label{TarjanPC}
\end{algorithm}

\noindent The graph in \Cref{graph22} shows the 5 strongly connected components identified after running Tarjan's algorithm \cite{tarjan1972depth} on the initial graph in \Cref{graph21}. Vertices that have the same background are part of the same component; meaning that one vertex can reach every other vertex in the component by following the directed edges. Note that some vertices make a component on their own as there is no way to reach them again in a cycle.

\noindent Tarjan\textquotesingle s algorithm \cite{tarjan1972depth} for finding strongly connected components is shown in Algorithm \ref{TarjanPC}. The \textit{Tarjan} procedure in line 1 takes a Graph $G$ as an argument and represents the start of the algorithm. The global integer $index$ declared in line 3 stores the current order in the depth-first search, and gets incremented each time a vertex is discovered. The integer $components$ in line 4 keeps track of how many components were identified in the given graph. The integer $n$ in line 5 represents the number of vertices in the given graph.

\noindent In line 6 a declaration is made for a \textit{Stack} data structure that will hold all the vertices that are part of the same strongly connected component. Line 7 contains a declaration for the $stacked$ vertex-indexed array of booleans used to keep track if a vertex is present or not on the stack $S$.

\noindent An integer vertex-indexed array $id$ is declared in line 8 to store the id of the strongly connected component of each vertex. Line 9 declares a vertex-indexed array $low$ used to store the topmost reachable vertex in the depth-first search tree through a back edge. Lines 10 and 11 contain a for loop that calls a procedure for performing depth first search on every vertex in the given graph that is not currently stacked.

\noindent Line 12 declares a recursive procedure for performing a depth-first search starting from vertex $u$ in graph $G$. The procedure starts by pushing the vertex $u$ on the stack $S$ (line 14) and then updating the value in the $stacked$ array (line 15) to reflect the change. Line 16 sets the vertex\textquotesingle s $v$ value for $low$ to $index$ as every vertex assumes to have no ancestors until a back edge to one is found. In line 17, the value for $index$ is incremented by one to keep count of the current number of discovered vertices. Line 18 declares an integer $min$ used to hold information about the oldest, lowest ancestor that will be discovered later in the search and is initialized to take the same value of the current vertex.

\noindent Lines 19 to 21 loop through every vertex $v$ that is a neighbour of vertex $u$. The procedure $N(u, G)$ on line 19 returns a list of neighbouring vertices of a given vertex, not including the given vertex. If the discovered neighbour $v$ is not currently on the stack $S$, then we proceed to make a recursive call to the depth-first search function on the found vertex.

\noindent After the recursive call finishes processing the sub-tree of the neighbouring vertex $v$, $min$ gets updated on line 21 to store the topmost reachable vertex that could be the same, or even higher in the tree if a higher back-edge from $v$ was discovered.

\noindent Line 22 updates the topmost reachable vertex of vertex $u$ to reflect any changes after processing all the neighbouring vertices. Line 23 declares an integer $v$ used to store a vertex that for the repeat-until loop in lines 24 to 28. The loop begins by popping vertices out of the stack $s$ on line 25. Each vertex $v$ found on the stack is assigned the current component id. Line 26 assigns the last leaf vertex of the graph as a topmost reachable vertex of vertex $v$ in order to mark it as already part of a component. The repeat-until loop in line 24 to 28 is runs until reaching the root of the component.

\noindent The depth-first search procedure finishes on line 29 by updating the total number of strongly connected components discovered.

\section{Deletion of edges from the graph}

\noindent The final step in the all-different algorithm uses the knowledge gained after computing a maximum matching and finding the strongly connected components in the graph. For this step, every edge that does not belong to any matching covering the vertices in the left partition of the graph will be deleted. The algorithm shown in Algorithm \ref{RemovePC} is a slight adaptation of the fourth and final step in Jean-Charles R\'egin\textquotesingle s paper \cite{regin1994filtering} describing the all-different constraint. The algorithm starts by computing a matching using the Ford-Fulkerson algorithm \cite{ford1956maximal}. Having the match, a breadth-first search is performed on the free vertices in the graph and traversed edges are marked as $used$. Tarjan\textquotesingle s algorithm \cite{tarjan1972depth} is then used to find the strongly connected components in the directed graph. Each edge connecting two vertices in the same component is marked as $used$. Finally, all the edges in the graph that are $unused$ and are not part of the matching will be deleted from the graph. The $unused$ edges represent edges that are not part of any alternating path of even length, and therefore belong to no possible matching in the value graph of the constraint. The removed edges in the graph correspond to values getting removed from the domains of the variables, and represents the way the search spaced for a solution is pruned.

\begin{figure}[H]
\begin{center}
\large
\begin{TAB}(e, 1.5cm, 1.5cm){|c|c|c|c|c|c|c|c|c|}{|c|}
18 & 23 & 23 & 245 & 456 & 456 & 279 & 378 & 23589
\end{TAB}
\end{center}
\caption{A Sudoku row used to illustrate the all-different algorithm}
\label{fig:row_1}
\end{figure}

\begin{algorithm}[H]
\DontPrintSemicolon
$\mathit{RemoveEdgesFromGraph}(\textbf{Graph}~G)$ \;
// \textit{RemovedEdges} is the set of edges removed from \textit{G} \;
// $M(G)$ is a matching over $G$ using the Ford-Fulkerson algorithm \cite{ford1956maximal} \;
// The function returns \textit{RemovedEdges} \;
\Begin{
    \nl Mark all the edges in graph \textit{G} as $unused$ \;
    \nl Initialize \textit{RemovedEdges} to the empty set \;
    \nl Compute a matching over \textit{G} using the FordFulkerson algorithm \cite{ford1956maximal}\;
    \nl Perform a breadth-first search starting from the free vertices and mark all visited edges as $used$ \;
    \nl Compute the strongly connected components of graph \textit{G} using Tarjan\textquotesingle s algorithm \cite{tarjan1972depth}\;
    \nl Mark each edge that connects two vertices in the same component as $used$ \;

\nl \For {\normalfont{each edge} $e$ \normalfont{in graph} $G$ \normalfont{that is} $unused$}{
 \eIf {$e$ $\in M(G)$}{ mark $e$ as $vital$ }{ \textit{RemovedEdges} $\gets $ \textit{RemovedEdges}$ ~ \cup ~ \{e\}$ \;
   Remove $e$ from $G$
 }
}
$\textbf{return} ~ \textit{RemovedEdges} $
}
\;
\caption{Remove edges from the value graph of a constraint of difference}
\label{RemovePC}
\end{algorithm}

\noindent The recently described last step of the all-different algorithm is the general implementation of the all-different constraint. The properties of the all-different constraints used in the Sudoku puzzle make the last step of the all-different algorithm much easier. It is good to notice that the chosen value graph used in this report has 18 vertices in two partitions. The Sudoku row shown in \Cref{fig:row_1} corresponds to the value graph that was used in this report and was chosen as an example to illustrate the effects of running the all-different algorithm on the 9 variables involved in the constraint. The value graph of the constraint is shown in \Cref{graph23}. The variables of the Sudoku row in the left $L$ partition of the value graph have names from A to I. Each variable has edges to vertices in the right $R$ partition of the graph representing digits in the domain of the variable. As all the constraints of difference in the Sudoku puzzle have 9 variables taking at most 9 possible values, the two partitions of the graph will always be balanced. This property makes the last step of the all-different constraint a straightforward process in the case of the Sudoku puzzle. This alternative algorithm for the last step in the all-different constraint considers only the edges that connect two vertices from different components of the value graph. Edges of interest are highlighted in \Cref{graph23}. The direction of the edges indicate two outcomes and are coloured in blue and red as shown in \Cref{graph24}. Forward edges (coloured in red) indicate that the digits from the right $R$ partition should be removed from the domain of the variables in the $L$ partition as they will never be part of an even alternating path and therefore cannot be part of a solution where the constraint holds. Backward edges (coloured in blue) indicate finding the unique assignment to a variable. In the case shown in \Cref{graph24}, the first variable $A$ of a selected Sudoku row will certainly take the value of $1$ as all other values got removed from its domain.

\noindent \Cref{fig:row_2} shows the final state of the Sudoku row after the last step in the all-different algorithm. Values coloured in red (underlined) correspond to edges that got removed from the value graph of the constraint. Values coloured in blue represent the unique value that is assigned to a variable as all other values from the domain got removed.

%grapht2start
\begin{figure}[H]
%graph23
\begin{minipage}{8.0cm}
\centering
\definecolor{applegreen}{rgb}{0.55, 0.71, 0.0}
\definecolor{amber}{rgb}{1.0, 0.75, 0.0}
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{americanrose}{rgb}{1.0, 0.01, 0.24}
%yellow

\psset{colsep=6cm, rowsep=0.3cm, arrows=->, arrowsize=6pt, arrowinset=0, radius=3cm}
\begin{psmatrix}
[mnode=circle][fillstyle=solid,fillcolor=babyblue]A&[fillstyle=solid,fillcolor=americanrose]1 \\
[fillstyle=solid,fillcolor=amber]B&[fillstyle=solid,fillcolor=amber]2 \\
[fillstyle=solid,fillcolor=amber]C&[fillstyle=solid,fillcolor=amber]3 \\
[fillstyle=solid,fillcolor=applegreen]D&[fillstyle=solid,fillcolor=applegreen]4 \\
[fillstyle=solid,fillcolor=applegreen]E&[fillstyle=solid,fillcolor=applegreen]5 \\
[fillstyle=solid,fillcolor=applegreen]F&[fillstyle=solid,fillcolor=applegreen]6 \\
[fillstyle=solid,fillcolor=yellow]G&[fillstyle=solid,fillcolor=yellow]7 \\
[fillstyle=solid,fillcolor=yellow]H&[fillstyle=solid,fillcolor=yellow]8 \\
[fillstyle=solid,fillcolor=yellow]I&[fillstyle=solid,fillcolor=yellow]9 \\
[mnode=none]L&[mnode=none]R 

\nccurve[angleA=180, offsetA=3pt, offsetB=3pt]{1,2}{1,1} % a > 1 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{2,1}{2,2} % b > 2
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{3,2}{2,1} % b > 3 X

\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{2,2}{3,1} % c > 2 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{3,1}{3,2} % c > 3

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{4,1}{2,2} % d > 2 
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{4,2}{4,1} % d > 4 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{4,1}{5,2} % d > 5

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{5,1}{4,2} % e > 4 
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{5,1}{5,2} % e > 5
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{6,2}{5,1} % e > 6 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{6,1}{4,2} % f > 4
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{5,2}{6,1} % f > 5 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{6,1}{6,2} % f > 6

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{7,1}{2,2} % g > 2
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{7,2}{7,1} % g > 7 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{7,1}{9,2} % g > 9

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{8,1}{3,2} % h > 3
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{8,1}{7,2} % h > 7
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{8,2}{8,1} % h > 8 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{2,2} % i > 2
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{3,2} % i > 3
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{9,1}{5,2} % i > 5
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{9,1}{8,2} % i > 8
\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=lightgray]{9,2}{9,1} % i > 9 X

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt]{1,1}{8,2} % a > 8


\end{psmatrix}
\caption{Edges connecting vertices in separate components}
\label{graph23}
\end{minipage}%
%graph24
\hfill
\begin{minipage}{8.0cm}
\centering
\definecolor{applegreen}{rgb}{0.55, 0.71, 0.0}
\definecolor{amber}{rgb}{1.0, 0.75, 0.0}
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{americanrose}{rgb}{1.0, 0.01, 0.24}
%yellow

\psset{colsep=6cm, rowsep=0.3cm, arrows=->, arrowsize=6pt, arrowinset=0, radius=3cm}
\begin{psmatrix}
[mnode=circle][fillstyle=solid,fillcolor=babyblue]A&[fillstyle=solid,fillcolor=americanrose]1 \\
[fillstyle=solid,fillcolor=amber]B&[fillstyle=solid,fillcolor=amber]2 \\
[fillstyle=solid,fillcolor=amber]C&[fillstyle=solid,fillcolor=amber]3 \\
[fillstyle=solid,fillcolor=applegreen]D&[fillstyle=solid,fillcolor=applegreen]4 \\
[fillstyle=solid,fillcolor=applegreen]E&[fillstyle=solid,fillcolor=applegreen]5 \\
[fillstyle=solid,fillcolor=applegreen]F&[fillstyle=solid,fillcolor=applegreen]6 \\
[fillstyle=solid,fillcolor=yellow]G&[fillstyle=solid,fillcolor=yellow]7 \\
[fillstyle=solid,fillcolor=yellow]H&[fillstyle=solid,fillcolor=yellow]8 \\
[fillstyle=solid,fillcolor=yellow]I&[fillstyle=solid,fillcolor=yellow]9 \\
[mnode=none]L&[mnode=none]R 

\nccurve[angleA=180, offsetA=3pt, offsetB=3pt, linecolor=blue]{1,2}{1,1} % a > 1 X
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=red]{1,1}{8,2} % a > 8

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=red]{4,1}{2,2} % d > 2 

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=red]{7,1}{2,2} % g > 2

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=red]{8,1}{3,2} % h > 3

\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=red]{9,1}{2,2} % i > 2
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=red]{9,1}{3,2} % i > 3
\nccurve[angleB=180, offsetA=3pt, offsetB=3pt, linecolor=red]{9,1}{5,2} % i > 5

\end{psmatrix}
\caption{Deletions (red, forward direction) and assignments (blue, backward direction) for the variables}
\label{graph24}
\end{minipage}%
\end{figure}
%grapht2end

\begin{figure}[H]
\begin{center}
\large
\begin{TAB}(e, 1.5cm, 1.5cm){|c|c|c|c|c|c|c|c|c|}{|c|}
\textcolor{blue}{1}\textcolor{red}{\underline{8}} & 23 & 23 & \textcolor{red}{\underline{2}}45 & 456 & 456 & \textcolor{red}{\underline{2}}79 & \textcolor{red}{\underline{3}}78 & \textcolor{red}{\underline{235}}89
\end{TAB}
\end{center}
\caption{Removal of values from the domain (in red, underlined), and assignments (in blue) in a Sudoku row}
\label{fig:row_2}
\end{figure}

\noindent Notice how in the row in \Cref{fig:row_2} it is certain that the first variable takes the value $1$ as no other variables have it as an option. Another interesting thing to notice is how the second and third variables both have $\{2, 3\}$ as their domain. The all-different algorithm works by spotting such Hall sets \cite{gent2008generalised}, where a Hall set is when $n$ variables have their domain equal to a subset of a set of values $D$ that has cardinality $n$. For each Hall set, one can remove the identified values from the domains of the neighbouring variables that were not part of the identified Hall set. For example, another Hall set in the mentioned row is between the $3$ variables that have the domains $\{4, 5\}$, $\{4, 5, 6\}$ and $\{4, 5, 6\}$, as $2$ got removed by the previously identified Hall set. This means that there are $3$ variables that together can take $3$ values: $\{4, 5, 6\}$. Knowing this, the digits $4$, $5$ and $6$ can be removed from the neighbouring variables as they will be consumed by the three variables in the Hall set, without knowing which variable will take which value.

\chapter{All-Different Demonstration}
\label{chap5alldiffdemo}

\noindent This chapter provides a demonstration of the Java program developed to solve Sudoku puzzles using Constraint Programming. The Graphical User Interface of the program is split into two parts, the left-hand side showing a Sudoku puzzle, while the right-hand side shows the value graph of an all-different constraint. Each time a row, column or $3 \times 3$ sub-square is selected by the user, the corresponding $9$ variables are highlighted in the Sudoku puzzle. The steps in the all-different algorithm perform changes on the graph of the selected constraint of difference.

\noindent Every Constraint Satisfaction Problem (CSP) has variables with domains associated to them and constraints that should hold for a solution. For the purpose of this project, there are 81 variables representing the $9 \times 9$ cells in the Sudoku grid, each with an initial domain of integers from $1$ to $9$ as shown in \Cref{screenshot1}. The aim is to reduce the domain of all the variables to a single value, the correct value that is part of the solution. As all initial Sudoku puzzles start with a partially completed grid, values that represent clues are reflected as variables that have an initial domain of a single value, the known digit. Such variables keep their initial assignment throughout the algorithm, as no other values are present in their domain.

\noindent The constraints for a Sudoku puzzle can be expressed in a natural language as such: ``digits may not appear twice in the same row, column or $3\times 3$ sub-square''. The rules of the puzzle highlight the need of thinking in terms of $9$ rows, $9$ columns and $9$ sub-squares, each of them having digits from $1$ to $9$ with no repetition. The Sudoku puzzle will therefore be modeled as a CSP \cite{simonis2005sudoku} that has $27$ all-different constraints, one for each of the $9$ rows, columns and sub-squares. Each constraint contains 9 variables that should take different values. As each variable is part of a row, column and sub-square, it is therefore involved in 3 constraints of difference at the same time.

\noindent One gets to the solution by running the all-different algorithm on rows, columns and sub-squares to remove values from the domain of the variables. Initially, the known values given at the start of the puzzle will be removed from the domains of possible values in the variables that are part of the same row, column or sub-square. As the algorithm progresses, it will eventually remove enough values from the domain of a variable until a single value is left, representing the correct answer for that position. Once a value is found, there is a waterfall-like effect across the puzzle as the knowledge is propagated across the grid. The propagation takes place across all the variables that are in the same row, column and sub-square with the one just solved. This keeps the 3 constraints of difference in a consistent state, as all the variables will have remaining domains not containing any already solved values. Initially, the propagation mechanism is disabled in the program such that all changes to the puzzle are made by the all-different algorithm that detects such inconsistencies and removes them. Propagation after assignments can be enabled from the Settings menu.

\noindent In order to test and show that the all-different algorithm is implemented correctly and performs the right decisions, a demonstration is hard coded consisting of running the all-different algorithm on a sequence of $5$ rows, columns and sub-squares. The step by step demonstration can be run using the \textit{Show demo} button and can be paused at any time. Alternatively, the same sequence can be followed by manually selecting the rows, columns and sub-squares mentioned in Appendix B.

\noindent The all-different algorithm consists of a number of operations performed on the value graph of a selected constraint of difference. All operations on the graph are shown in a step by step fashion in the right-hand side of the screen. First, a greedy match is performed on the graph to associate most of the variables with a value. The second step is to compute a maximum matching for the $9$ variables in the left partition of the graph. The maximum matching is computed using the Ford-Fulkerson algorithm  \cite{ford1956maximal} introduced in \Cref{ffsection}. \Cref{screenshot1} shows the maximum matching for the constraint of difference in the 1st column of the puzzle. The third step uses information from the maximum matching to find the strongly connected components in the value graph of the constraint, by using Tarjan\textquotesingle s algorithm \cite{tarjan1972depth} introduced in \Cref{tarjansection}. \Cref{screenshot2} shows vertices belonging to the same component having the same background colour. Finally, the edges connecting vertices that belong to different components get colored in red or blue based on their direction. Red edges connect a variable with a value that was removed from its domain during the algorithm. Blue edges highlight the single value a variable is forced to take, as it is the only option left in its domain. The state of the 1st column after running the all-different algorithm is shown in \Cref{screenshot2}. Notice how the all-different algorithm performs changes only to the selected 9 variables inside a row, column or $3\times 3$ sub-square.

\begin{figure}[H]
\begin{minipage}{8.0cm}
\centering
\includegraphics[width=8cm]{images/proof_of_concept/screenshot1.png}
\caption{1st column after finding a maximum matching}
\label{screenshot1}
\end{minipage}%
\hfill
\begin{minipage}{8.0cm}
\centering
\includegraphics[width=8cm]{images/proof_of_concept/screenshot2.png}
\caption{1st column after running the all-different algorithm}
\label{screenshot2}
\end{minipage}%
\end{figure}

\vspace*{-0.5cm}

\noindent The same steps are followed for the 5th row (\Cref{screenshot3}), the 6th row (\Cref{screenshot4}) and the 4th $3\times 3$ sub-grid (\Cref{screenshot5}). As seen in the figures mentioned before, all the previous runs of the all-different algorithm removed values from the domain of the variables that represented clues in the initial puzzle. Notice how in \Cref{screenshot5} there are two variables in the 1st column of the puzzle, each having a domain of $\{1, 8\}$. One does not know which of the two variables will take which value, but since the two values will have to be used by the two variables, this means both values should be removed from the other variables in the same constraint. This detail is spotted by the all-different algorithm that decides to remove the two values from the domains of the neighbouring variables. The last selection in this demonstration calls the all-different algorithm on the 1st column of the puzzle once again. \Cref{screenshot6} shows the state of the 1st column after running the all-different algorithm the second time. Notice how only two variables in the 1st column have the values $1$ or $8$ in them, compared to last time. It is good to mention once again that the all-different algorithm does not make guesses, instead it looks for Hall sets \cite{gent2008generalised} in the graph to remove values from the domains of the variable that will never be part of a solution.

\noindent The algorithm is intelligent in a sense that it mimics the human strategy when solving a Sudoku puzzle. At some stages of the game there is enough information to know that, for example, two particular values will fill two cells, but no information about which value corresponds to which cell. The hardness of a Sudoku puzzle increases with the number of such dilemmas, and the number of variables having the same values in their domain \cite{gomes2002completing}. By using the all-different algorithm, one can ensure the progress towards a solution, despite not knowing which value goes where. It is good to note that although humans may choose a guessing approach to continue towards a solution, the all-different algorithm performs no guessing and works only with the information about the current state of the puzzle.

\begin{figure}[H]
\begin{minipage}{8.0cm}
\centering
\includegraphics[width=8cm]{images/proof_of_concept/screenshot3.png}
\caption{5th row after running the all-different algorithm}
\label{screenshot3}
\end{minipage}%
\hfill
\begin{minipage}{8.0cm}
\centering
\includegraphics[width=8cm]{images/proof_of_concept/screenshot4.png}
\caption{6th row after running the all-different algorithm}
\label{screenshot4}
\end{minipage}%
\vspace*{1cm}
\begin{minipage}{8.0cm}
\centering
\includegraphics[width=8cm]{images/proof_of_concept/screenshot5.png}
\caption{4th $3\times 3$ sub-grid after running the all-different algorithm}
\label{screenshot5}
\end{minipage}%
\hfill
\begin{minipage}{8.0cm}
\centering
\includegraphics[width=8cm]{images/proof_of_concept/screenshot6.png}
\caption{1st column after running the all-different algorithm}
\label{screenshot6}
\end{minipage}%
\end{figure}

%\vspace*{-1cm}

\begin{figure}[H]
\centering
\includegraphics[width=14cm]{images/proof_of_concept/screenshot7.png}
\caption{State of the program after running the demo}
\label{screenshot7}
\end{figure}

\noindent The end result of following the $5$ steps in the demonstration can be seen in ~\Cref{screenshot7}. In the 1st column there are two cells with a domain of ${1, 8}$. Although, one does not know yet which cell takes which value, the human and the all-different algorithm is sure that the digits ${1, 8}$ will be distributed to the two particular cells. The last step illustrates the all-different algorithm decision to remove the values ${1, 8}$ from the domains of the rest of the cells in the selection.

\chapter{Implementation}
\label{chap6implementation}
\noindent This section describes the program that was made to showcase how the all-different algorithm works. The programming language used throughout the project is \textit{Java}, a popular language that supports Object Oriented Programming. One of the most important benefits of using Java for this project is that it is platform-independent, meaning that the same source code can be compiled to run on different processors and Operating Systems, allowing for greater portability. Java\textquotesingle s standard library includes support for concurrency, building the Graphical User Interface (using the \textit{Swing} library), and various data structures that are needed in the project.

\noindent Two classes \textit{Var} (variable) and \textit{Constraint} are used to model the Sudoku problem as a Constraint Satisfaction Problem. Each of the cell in the Sudoku puzzle gets represented as a variable that has an initial domain set to a single digit (in the case of the clues present in the initial puzzle) or an initial domain of digits from $1$ to $9$ for blanks in the original puzzle. The \textit{Constraint} class is used to specify that variables in the same row, column or sub-square should be all different. The constraints are used throughout the program to check if they still hold in a solution or it they are consistent with each other during the search for a solution.

\noindent From a high-level view, the Model-View-Controller (MVC) design pattern was chosen for the program\textquotesingle s architecture. By using a MVC architecture one can achieve a clean separation of concerns, where the Model object encapsulates the data and defines the operations that can done on that data, while the View object reads the data from the Model and presents it to the User. Controller objects are used to link the Model to the View by communicating changes such as User input that update the state of the Model and the View. In practice, most of the time the View and Controller roles are combined as an object that is responsible for rendering the User Interface and handling events such as mouse clicks.

\noindent The program reads partially completed Sudoku puzzles from \textit{.txt} files that can be opened by choosing the option from the File menu. Files should contain $9$ rows filled with digits from $1$ to $9$, separated by spaces, representing clues in the initial puzzle. Unknown values in the initial puzzle that have to be filled by the player are represented in the file by the $0$ digit. By default, the program tries to load the \textit{lockedset.txt} file used in the demonstration that is stored in the \textit{puzzles} directory inside the current working directory. Alternatively, if the default file is not found, the User should choose a file from his hard drive to open.

\noindent The Graphical User Interface (GUI) is inside a \textit{JLayeredPane} which is a special \textit{Swing} component that allows components inside it to overlap according to their specified depth. In this program, the backmost layer contains a \textit{JPanel} responsible for the drawn edges in the graph. The layer above contains the rest of the GUI represented by the Sudoku puzzle on the left-hand side of the screen, and the vertices of the graph on the right-hand side of the screen. By using a layered panel, the edges of the graph can be drawn behind the vertices.

\noindent The Sudoku Grid is rendered on the left-hand side of the screen and is made up of $9 \times 9$ Sudoku Cells positioned at specific locations. Each Sudoku Cell is aware of its position in the grid and has a square \textit{JPanel} to textually render the current domain of a variable to visualize the markup of the puzzle \cite{crook2009pencil}. The border of the \textit{JPanel} has different widths according to the position of the variable in the grid.

\noindent Not visible to the human eye, a new Sudoku grid instance is drawn on top of the existing one, this time with all borders set to a width of 1px. The Sudoku Cells inside this second grid contain the same information about the state of the puzzle retrieved from the Model. Additional information such as a custom background will be applied to these cells as the algorithm progresses. Cells inside the second grid become visible once the user makes a selection. Once visible, the cells inside the selection are animated into their position inside the graph on the right-hand side of the screen. When the user deselects his choice, the nice cells are animated back into their original position in the grid and become invisible again.

\noindent Small adjustments had to be made to the size and alignment of the components, and the size of the fonts such that the Graphical User Interface would look as intended across different Operating Systems. Although Java is platform-independent, meaning that the same code will run across platforms supporting Java, challenges in rendering the User Interface remain as each Operating System specifies its implementation for the specified font family. For example, Windows renders Serif fonts smaller than Mac OS does.

\noindent Digits in each cell of the Sudoku grid are printed as graphics using the \textit{drawString} method from the Graphics2D object associated to all GUI components. This approach was used to allow for a more precise alignment of the characters having different widths, as opposed to separating them using spaces. The borders in the Sudoku grid, and edges in the value graph of a constraint were made using the \textit{drawLine} method of the Graphics2D object. The circles representing vertices in the right partition of the graph were made using the \textit{fillOval} method.

\noindent The all-different algorithm is implemented as a method in the Model. The algorithm consists of multiple operations done on a bi-partite directed \textit{Graph} representing the value graph of a constraint of difference. For the purpose of this project, the graphs and the operations on the graphs were programmed in a procedural way, as this allows for fewer and more readable lines of code. Graphs are represented as a $v \times v$ adjacency matrix (where $v$ is the number of vertices in the Graph) filled with $0$ and $1$ to reflect if an edge exists between two vertices. Note that the adjacency matrix is not necessary symmetric, which allows specifying the direction of the edges. The graph is built with information that is read from the Model about the currently selected row, column or $3 \times 3$ sub-square. First, the Ford-Fulkerson algorithm  \cite{ford1956maximal} is used to compute a maximum matching over the $9$ selected variables. Note that the Ford-Fulkerson algorithm uses two extra vertices called the $source$ and the $sink$ connected to the partitions of the graph with edges that have to be specified in the adjacency matrix of the graph. The Ford-Fulkerson algorithm is implemented according to the pseudo-code specified in Algorithm \ref{FordFulkersonPC}. The second step is to compute the Strongly Connected Components in the graph using Tarjan\textquotesingle s algorithm \cite{tarjan1972depth} shown in Algorithm \ref{TarjanPC}. Note that this step no longer uses the $source$ and $sink$ vertices from the previous step and changes should be made to the  adjacency matrix to reflect this. Finally, only the edges that have a forward direction connecting a variable with a value from separate components are considered. Based on this final state of the graph, the values will be removed from the domain of the variables their are linked to. Each time a change occurs in the graph, the Model informs the View Controller that it needs to refresh to reflect the new changes stored in the Model.

\noindent The propagation mechanism used in this project represents the AC-3 algorithm developed by Alan Mackworth \cite{mackworth1977consistency} in 1977. This 3rd revision of the Arc Consistency algorithm is more efficient than previous ones and one of the most often used because of its simplicity. The algorithm checks that all the constraints in the problem are consistent by considering all the pairs of variables in each constraint. When an inconsistency is found, such as when a variable still has a value in its domain that is already assigned to another variable, it gets removed from the first variable. Such inconsistencies occur after running the all-different algorithm, since the all-different algorithm only performs changes on the $9$ variables of a row (for example) resulting in the need to update the intersecting columns and sub-squares to reflect the changes made. Each time a value gets removed from the domain of a variable, the algorithm rechecks the other constraints the variable is part of to see if they are still consistent after the removal. The algorithm is guaranteed to finish after no more removal of values occur and all the constraints are checked. This algorithm is efficient in the sense that changes to the domains of a variable trigger a waterfall-like checks only on the variables that have a constraining relationship with the first one, as opposed to rechecking all the variables and the constraints of the problem.

\noindent The user selects which row, column or sub-square to solve next by clicking the first variable of the row/column, or the center of the sub-square. A selection triggers the movement of the row, column or sub-square to the right-hand side of the screen to be made part of the graph, all in an animated fashion. The selection is highlighted in the Sudoku puzzle, while the rest of the grid is faded out to let the user know that the all-different algorithm performs changes only on the $9$ variables that are part of his selection. \textit{Timer} objects are used to schedule repeated actions such as the fading out of the components or movement of the Sudoku cells. The Model contains a two-dimensional \textit{ArrayList} of \textit{Timer} objects that acts as a queue of animations. Timers on the same level start running at the same time until they all finish. Once all the timers on a level finish, the next level in the two-dimensional \textit{ArrayList} is started, allowing us to queue a movement of a row after all the cells finish fading out. The user can deselect his choice before or after running the all-different algorithm, resulting in an animation that returns the selection to the original position in the Sudoku grid and fading in the puzzle so it is visible again.

\noindent The program includes a button used to play a demonstration of the all-different algorithm. The button calls the selection method, the all-different method and the deselection method for 5 rows, columns and sub-squares in a sequential way. The demonstration runs only if there is currently no selection made and the loaded Sudoku puzzle is the \textit{lockedset.txt} file.

\noindent The pause/play mechanism used throughout the program to control the flow of the animations works by pausing the logic thread. The implementation consists of specifying multiple checkpoints at relevant steps in the animation where the program checks if the user requested that the animation should be paused. A synchronized $Object$ acts as a \textit{lock} throughout the program. The \textit{wait} method is called on the $lock$ whenever the user requests a pause in the animation. The \textit{notify} method is called to resume the animation from where it was paused. As the program uses \textit{Timer} objects to perform repetitive tasks, all the timers will be stopped and started according to the user\textquotesingle s needs by calling the methods \textit{stop} and \textit{start}.

\noindent The lower part of the User Interface includes a \textit{JSlider}, which is a slider that can be used by the User to adjust the speed of the animation. The slider represents a bounded interval of speeds ranging from slow to fast. The speed of the animation is controlled by specifying how much the logic thread should sleep when solving the problem and by what distance components should move during the animation. Note that only the logic thread is put to sleep and not the thread responsible for the program\textquotesingle s interface, as this would freeze the Graphical User Interface and make it unresponsive.

\noindent Particular attention was given to make the software thread safe. It is crucial that the program\textquotesingle s logic does not make the Graphical User Interface unresponsive. To achieve this, the program will run on two threads, one main thread responsible with all the processing need to be done by the program, and the Event Dispatching Thread. The Event Dispatching Thread (EDT) is a background thread used to invoke Swing methods that change the GUI and listen to events associated to components. Most Swing components are not thread safe, therefore bugs such as race conditions could unexpectedly arise if it was to perform the actions from normal threads. The EDT acts as a queue of events that are performed sequentially. The \textit{Timer} objects used throughout this project to perform animations send events to the specified listeners making it crucial that the EDT does not get blocked.

\noindent A backtracking algorithm was implemented to solve the Sudoku puzzle by choosing values from the domains of the variables in the Sudoku puzzle. The algorithm goes through each available value in the domain of a variable, assigns it as its guess and calls the propagate method. If the value selected breaks a constraint, the propagate method will report this inconsistency that triggers the backtracking from that point. This method is slow as it does not use the all-different algorithm to prune the search space of the problem of such values that break the constraints. Alternatively, the user can solve the puzzle using the open-source \textit{Choco3} library \cite{choco} that is used to model Constraint Satisfaction Problems in Java. The implementation models the currently loaded Sudoku and solves it using the same algorithms used in this project to provide proof that the solution found is the correct one.

\chapter{Conclusion}
\label{chap7conclusion} 
\section{Summary}
The aim of this project was to develop a Java program to be used during Constraint Programming lectures to introduce students to the all-different algorithm. This report started by introducing general concepts from Constraint Programming, a programming paradigm that originated from Artificial Intelligence. A chapter is dedicated to reviewing Jean-Charles R\'egin\textquotesingle s paper \cite{regin1994filtering} from 1994 describing the all-different constraint. The algorithm is a sequence of steps that perform operations such as finding a maximum matching and the strongly connected components in the value graph of a constraint of difference. The Ford-Fulkerson algorithm \cite{ford1956maximal} was used in this project to compute the maximum matching, and Tarjan\textquotesingle s algorithm \cite{tarjan1972depth} to find the strongly connected components in the graph. The Sudoku puzzle was chosen to illustrate the steps in the all-different algorithm. A Java program was developed to model the problem and provide a Graphical User Interface showing the puzzle and the value graphs of the all-different constraints. A description of the algorithms used and how the project was implemented in Java is provided in the paper.

\section{Future Work}
\noindent The program developed in this project implements a model for the popular Sudoku puzzle that has a $9 \times 9$ grid. There are multiple techniques and algorithms to solve such a puzzle in approximately the same time using a regular CPU. It is therefore difficult to accurately measure the performance of the algorithms since searching for a solution takes only hundreds of milliseconds. The benefits of using Constraint Programming to solve such problems, using techniques such as the all-different algorithm presented in this report, starts to become observable when trying to solve a bigger Sudoku grid, such as one of size $36 \times 36$. The performance in such a case is a matter of seconds, compared to hours or even days as shown in the experiments made by Stergiou and Walsh \cite{stergiou1999difference} who approached the Quasigroup completion problem \cite{gomes2002completing}, a problem that uses the same constraints as the Sudoku puzzle. Future work could mean developing models and a Graphical User Interface for general $n^2\times n^2$ sized boards, along with a way to compare the performance of different algorithms.

\noindent Another interesting avenue for future work is to implement and make use of different heuristics that may prove to increase the performance of the program when trying to find the solution. The project uses human judgments as its heuristic, as one has to select which row, column or $3 \times 3$ sub-grid to solve next. An example of such a heuristic is one that will check which selection has variables with many values in their domains, as there may have values that are more likely to fail by breaking a constraint.

\section{Personal Reflection}
As a Joint Honours student who studies Computing Science and Business Management, I have come to appreciate the importance of an efficient algorithm over an expensive hardware upgrade. Powerful algorithms such as the one in this report can offer a great competitive advantage in business environments that deal with hard combinatorial problems on a daily basis. Such an example would be the scheduling of the deliveries that need to be made the next day, where an optimal solution should be found in a matter of hours. In the end I would like to quote Robert Tarjan \cite{tarjanart}, winner of a Turing Award, on the characteristics of a good algorithm: ``It is one thing to have an algorithm that is theoretically good. It is another to have an algorithm that is simple enough that someone would want to program it and use it in practice''.

\section{Acknowledgements}
\noindent I would like to thank my supervisor, Dr.~Patrick Prosser, and Ciaran McCreesh, for all their guidance and feedback provided throughout this project.

%%%%%%%%%%%%%%%%
%              %
%  APPENDICES  %
%              %
%%%%%%%%%%%%%%%%
\begin{appendices}
\chapter{Running the Program}
Running the program from the command line is done after compiling the source code as follows:
\begin{verbatim}
      > javac *.java
      > java Sudoku
\end{verbatim}
This will open the program loaded with the Sudoku puzzle $\textit{/puzzles/lockedset.txt}$.

\noindent Detailed debug output in the console can be activated using:
\begin{verbatim}
      > java Sudoku debug
\end{verbatim}

\noindent NOTE that the Choco3 library \cite{choco} found in $\textit{lib/choco-solver-3.3.1-with-dependencies.jar}$ has to be added to the CLASSPATH environment variable as follows:

\begin{verbatim}
      > export CLASSPATH=$CLASSPATH:/path/to/the/lib/choco-solver-3.3.1-
with-dependencies.jar
\end{verbatim}

\noindent Alternatively, one could simply run the program from the \textit{.jar} file that contains all necessary libraries as follows:
\begin{verbatim}
      > java -jar sudoku.jar
\end{verbatim}


\chapter{Proof of concept}
\label{chapterpoc} 
The following sequence of steps provide a visual proof of the all-different algorithm. The following steps require the user to run the all-different algorithm on 5 predetermined rows, columns or $3\times 3$ sub-grids. For demonstration purposes, the Sudoku instance used is $/puzzles/lockedset.txt$.

\noindent The sequence is as follows:
\begin{verbatim}
      > Open lockedset.txt Sudoku instance
      >
      > Select the 1st column
      > Run the all-different algorithm
      > Deselect the column
      >
      > Select the 5th row
      > Run the all-different algorithm
      > Deselect the row
      >
      > Select the 6th row
      > Run the all-different algorithm
      > Deselect the row
      >
      > Select the 4th 3x3 sub-grid
      > Run the all-different algorithm
      > Deselect the sub-grid
      >
      > Select the 1st column
      > Run the all-different algorithm
      > Deselect the 1st column
\end{verbatim}

\noindent Alternatively, the user can press the $Show Demo$ button to run the same steps.

\noindent Detailed description about why the last state of the program is a proof that the algorithm works as expected is provided in Chapter~\ref{chap5alldiffdemo}.
\end{appendices}

%%%%%%%%%%%%%%%%%%%%
%   BIBLIOGRAPHY   %
%%%%%%%%%%%%%%%%%%%%

%\bibliographystyle{plain}
%\bibliography{mybib}
\printbibliography

\end{document}
